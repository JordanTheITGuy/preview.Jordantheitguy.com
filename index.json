[{"categories":["Intune"],"content":"How to find potentially risky files with LOG4J risks","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"On December 10th 2021 CVE-2021-44228 was unveiled- queue the mass panic. A simple logging component which had been around for… forever in a whole bunch of things including but not limited to Minecraft. Update: February 6th 2022 - It’s worth nothing that even now three months later this vulnerability is still having massive impact all over the world as the threat hunting methods originally devised were limited in their nature. In fact, we have even seen cases where grey hat hackers were using the exploit to patch the exploit. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:0:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Vulnerability Hunting V.S. Exploit Hunting DANGER: READ THIS Before you read any further, let me be clear, finding a “file” that has or is vulnerable to this exploit this is not the end of dealing with this vulnerability. I have tried to cover all the scenarios I can think of, however I am not a genius and there is no way to write this for every possible scenario. It’s one half of the whole. You absolutely need to start continuously hunting for the behaviors attackers would use this class for, while constantly checking for the existence of it in your environment. Hunting this threat is in and of itself challenging. When the vulnerability first came out there were several scripts that floated around the internet geared towards hunting the hashes of the vulnerable files. However as things continued to develop people started to ask – do these hashes change if someone nests a JAR inside a JAR? Additionally, what if an attacker changes the name of the product or the class is referenced in another JAR? And how do we tell the difference between something that is just not updated, and something being exploited? For more reading on that I suggest the following MSTIC team articles: Defender for Cloud finds machines affected by Log4j vulnerabilities Microsoft’s Response to CVE-2021-44228 Apache Log4j 2 – Microsoft Security Response Center ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:1:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"What can you do today with Intune Proactive Remediations? In Configuration Manager we have CI’s and they work amazingly well for hunting the state, and contents of specific files. I’m going to put a second disclaimer here, don’t use this script as an end all to everything. There is no one size fits all for this vulnerability, and in fact just saying “we patched all good” might not even be good enough for a while. Since last week, I’ve written three or four different methods to try and detect “do we need to patch this vulnerability.” All three of these methods have different pros’s and cons based on number of files, age of device, and are you looking for obfuscations. In general people have landed on three main different methods. Hash Validation, based on file name File Name Detection File Extension Detection and Class Validation The script I’m going to show uses the last of these three options. All of these have their own unique pro’s and con’s. I could spend hours on these, but I don’t think that’s why you’re here if this is something you’re interested in let me know and maybe I’ll do some type of follow up. If you’ve never created a Proactive Remediation before, rejoice because the most complicated part of creating one, is finding where they are located. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:2:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"The Script for the Proactive Remediation This article assumes you know how to create a proactive remediation, and will only be covering an explanation on the script used for detection. #Warning on potentially could scan synced sharepoint libraries. #Note this is using CIM instance - this will NOT work for old Servers and is not intended to be used on them. $drives = (Get-CimInstance -Query \"Select DeviceID from win32_logicaldisk where drivetype = 3\").DeviceID #Set the search string we are hunting for. $searchString = \"*.jar\" #Add type for reading the JarFiles Add-Type -AssemblyName \"system.io.compression.filesystem\" #Create an object to store found risks $foundRisks = New-Object -TypeName 'System.Collections.Generic.List[psobject]' Foreach ($drive in $drives) { #Assemble the risky files for the drive. $riskyFiles = (\u0026cmd /c robocopy /l $(($drive) + '\\') null \"$searchString\" /ns /njh /njs /np /nc /ndl /xjd /mt /s).trim() | Where-Object { $_ -ne \"\" } #Evaluate each set of risky files to see if there is anything to Evaluate. Foreach ($file in $riskyFiles) { $data = $null $detections = $null try{ #Warning this could could potentially create a lock on a Jar file - we do dispose of the connection and read at the end but based on size it could take a moment. $data = [io.Compression.Zipfile]::openRead($file) $detections = $data.Entries | Where-Object {$_.fullname -like \"*jndiLookup.class\"} $data.Dispose() } catch{ $hash = [ordered]@{ fileName = $file class = \"UnableToRead\" fileHash = $((Get-FileHash -Path $file -Algorithm SHA256).Hash) } $foundRisks.add((New-Object -TypeName psobject -Property $hash)) } if($detections){ foreach($detection in $detections ){ $hash = [ordered]@{ fileName = $file class = $detection.FullName fileHash = $((Get-FileHash -Path $file -Algorithm SHA256).Hash) } $foundRisks.add((New-Object -TypeName psobject -Property $hash)) } } } } If ($($foundRisks | Measure-Object).count -ge 1) { foreach($risk in $foundRisks){ #Assemble a Single Large Write Host Command for PR $jumboTune = \"$jumboTune Found: $($risk.FileName) with Hash:$($risk.fileHash) and Class: $($risk.class)`n\" } Write-Host $jumboTune exit 1 } Else { Write-Host \"No Vulnerabilities found\" exit 0 } What’s so special about this script? Well, it’s fast. No seriously it’s REALLY fast. We are talking evaluate every file in 600GB in ~19 seconds fast. Most of this is thanks to Robocopy. Now let’s break down the code and what’s happening here. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:3:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Initial Gathering of Drives #Note this is using CIM instance - this will NOT work for old Servers and is not intended to be used on them. $drives = (Get-CimInstance -Query \"Select DeviceID from win32_logicaldisk where drivetype = 3\").DeviceID #Set the search string we are hunting for. $searchString = \"*.jar\" #Add type for reading the JarFiles Add-Type -AssemblyName \"system.io.compression.filesystem\" #Create an object to store found risks $foundRisks = New-Object -TypeName 'System.Collections.Generic.List[psobject]' Nothing fancy here, just know that this is using CIM instance, assuming you’re using this script in Intune, you should only have machines that support this command. Additionally we set our search string – in this case anything that ends with “*.jar”. We add a type assemble – more on that later, and then create a list of PSObjects. Didn’t have to do that, but I like to use lists it’s a habit from when I’m not sure what version of PowerShell is in play. We then iterate over each drive and do the following: ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:3:1","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Gather Risky Files $riskyFiles = (\u0026cmd /c robocopy /l $(($drive) + '\\') null \"$searchString\" /ns /njh /njs /np /nc /ndl /xjd /mt /s).trim() | Where-Object { $_ -ne \"\" } #Evaluate each set of risky files to see if there is anything to Evaluate. Foreach ($file in $riskyFiles) { $data = $null $detections = $null try{ #Warning this could could potentially create a lock on a Jar file - we do dispose of the connection and read at the end but based on size it could take a moment. $data = [io.Compression.Zipfile]::openRead($file) $detections = $data.Entries | Where-Object {$_.fullname -like \"*jndiLookup.class\"} $data.Dispose() } catch{ $hash = [ordered]@{ fileName = $file class = \"UnableToRead\" fileHash = $((Get-FileHash -Path $file -Algorithm SHA256).Hash) } $foundRisks.add((New-Object -TypeName psobject -Property $hash)) } The first line leverages Robocopy, to gather only the string to file names using the /l command and some other switches to turn off the noise and speed ups the process of gathering the files. This then provides a list full of files with “*.Jar” at the end. Now it’s time to go to work. We use the IO.Compression.ZipFile class to open and read the contents of each of the .JAR file. We then look at all of the “entries” for anything that has the jndiLookup.class. We look for this, because if we find the class, we can be reasonable sure regardless of if there is a hash match, or if the file names don’t match that the machine is potentially at risk. We then add some important bits like where the file is located and it’s hash to our storage and continue on. We could just as easily swap this out for any of the other methods, validating if the .jar matches the known hash lists, or just reporting based on the name of the jar. If ($($foundRisks | Measure-Object).count -ge 1) { foreach($risk in $foundRisks){ #Assemble a Single Large Write Host Command for PR $jumboTune = \"$jumboTune Found: $($risk.FileName) with Hash:$($risk.fileHash) and Class: $($risk.class)`n\" } Write-Host $jumboTune exit 1 } Else { Write-Host \"No Vulnerabilities found\" exit 0 } Finally here at the end we compound together the names of the potentially vulnerable files, and write them to the host screen before existing with Exit Code 1 to properly send “risk” back to Intune. Once the script runs based you should get some nice outputs which you can then use to evaluate and start to make decisions on what should or shouldn’t be remediated. Keep in mind this doesn’t fix the issue as fixes will continue to evolve. This just helps you identify the problem. Here is an example of what the output looks like on my home machines, which happened to have an old copy of Minecraft on it. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:3:2","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Closing Thoughts I urge you to keep in mind that this is an evolving threat. The first “patch” to remediate the CVE was found to not always work. The second one encouraged people to just flat out remove the jndi lookup.class from the class path. I wouldn’t be surprised if we find several more things along the way. Your mileage may vary on how you look for vulnerability and I encourage you to think about what you are hunting for. Happy Patching. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:4:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["ConfigMgr"],"content":"A speedy guide on how to convert Update ID's","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"If you’ve ever worked with Automatic Deployment Rules, at some point an update has failed to download. While you might be familiar with the RuleEngine.log file, did know the “updateID” is the “CI_ID”? If you’ve ever tried to find a software update via CI_ID, you know you’re going to one of two places, and neither of them is the console. Essentially, if you’re here you’re looking for an easy way to figure out what update caused this error: For those of you who already know what this is and just want the quick answer here you go: ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:0:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"PowerShell Method #Enter the site code here $siteCode = \"XYZ\" #Enter the CI ID $ciID = \"11111111\" Get-CimInstance -ClassName SMS_SoftwareUpdate -Namespace \"root\\SMS\\site_$($SiteCode)\" -Filter \"CI_ID = $($ciID)\" | Select-Object LocalizedDisplayName,DateCreated ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:1:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"SQL Method --Where XXXXX is the update ID from the logs with an error SELECT * FROM v_UpdateInfo WHERE CI_ID = 'XXXXXX' --or for more strategic data SELECT dbo.v_UpdateInfo.CI_ID , dbo.v_UpdateInfo.ArticleID , dbo.v_UpdateInfo.Title , dbo.v_UpdateInfo.CI_UniqueID , dbo.v_UpdateInfo.InfoURL FROM v_UpdateInfo WHERE CI_ID = 'XXXXX' ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:2:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"What Does this Error Mean? In this scenario, the ADR has failed because it was unable to download content an example error for this might be: Failed to download ContentID 16778383 for UpdateID 16779809. Error code = 404 While this might be a pretty simple error (Can’t download the content, content not found, cause I deleted it) – what’s not clear is the name of the update causing the issue, and trying to determine the name of the update from a series of numbers might be frustrating. ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:3:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"Getting Update Info with PowerShell If you’ve worked with Configuration Manager for any length of time then you know it’s all WMI at the end of the day. In this case, software updates and their information exist within the Site Namespace, and have a class called “SMS_SoftwareUpdate”. You can actually retrieve all of the updates, and their associated properties by just requesting the objects that are of type SMS_SoftwareUpdate. This is pretty simple to get using the below line. When you do this, make sure you update line with your site code. This is pretty neat as you can get a lot of general information about software updates directly via PowerShell. Get-CimInstance -ClassName SMS_SoftwareUpdate -Namespace \"root\\SMS\\site_DM6\" If we take a close look you can see the CI_ID field here which of course means you can filter on it as was done in the example at the top of the article, so in this case we could run: #Enter the site code here $siteCode = \"XYZ\" #Enter the CI ID $ciID = \"16779809\" Get-CimInstance -ClassName SMS_SoftwareUpdate -Namespace \"root\\SMS\\site_$($SiteCode)\" -Filter \"CI_ID = $($ciID)\" | Select-Object LocalizedDisplayName,DateCreated With this we get the below output which includes the date the update was created, and the name of the update causing the issue. ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:4:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"Getting Information with SQL We can also get this information from SQL. Fortunately the SQL information is a little more transparent in my opinion, because CI_ID is the primary key which is used in a lot of locations across the Configuration Manager Database. For this use case it’s the primary key in the view: v_UpdateInfo If we run a select * from this view we will find all of the pieces we need for this particular puzzle, and from there we can create the SQL query like we did above to find out the name of the update which was causing this issue. ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:5:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["Security"],"content":"Defender for Endpoint making a Client Secret to access Data, can sometimes be useful if properly controlled","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Part Two on Getting Data from Defender for Endpoint This blog is the second post in a multipart series on how to get data from Defender for endpoint and analyze the patching data that is returned. Previously, we covered how to build a token, and request data from the Defender for endpoint API. This time we will cover how to create an azure app registration that allows the minimum required permissions to gather this data. To refresh your memory on what data, and how we would acquire said data, give a read back over part one. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:0:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"What is an Azure App Registration An azure app registration, can be a rather exhaustive conversation. The core usage is to provide authentication to allow a user, or a service access to an azure tenant. Azure app registrations have changed over the years. This includes changes to the authentication library they use, and the granularity of permissions they allow. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:1:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Azure App Registration Requirements To create an azure app registration in a tenant you need some special permissions. You need to not only be able to create the app registration, but you also need to be able to approve the usage of those permissions in your organization. To do this, you will need one of three different roles. Application Administrator Application Developer Cloud Application Administrator You can read more about quickly setting up any type of app registration here: ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:2:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Creating an App Registration for Defender for Endpoint Lets walk through the process to create an azure registration that we could use to complete the earlier released post. To register, you will first need to login at portal.azure.com and then navigate to app registrations. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Creating a registration This will then launch the AAD registered apps portal, and launch the applications list blade. From here you can create a new registration, see existing registrations or troubleshoot issues. If you are not familiar with this section, this is also where you would see how your CMG connects to Azure, desktop analytics and more. For this, we will simply select ‘New Registration’ Selecting this will open the window to start creating a new registration. Creating a registration is pretty simple, just enter a name choose the scope of who can use it and give it a name. For our example, I have given the app a name ‘Defender For Endpoint API. Once you click register at the bottom of the screen you will then be presented with a small box in the top right once the app is created. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:1","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Permissions for the App Once the application exists we are ready to start adding permissions to the application. Before we add any permission we can go ahead and remove the User.Read permission as we will not need it. To do this click the three dots on the far right and select delete. We can do so by using the add a permission button under the API permissions node. This will then launch the request API permissions section. From this section select the option ‘APIs my organization uses’ This will then let you search a lot of the build in API’s that are available in the portal. We want to search for Windows Defender ATP. Then we will want to select Application Permissions to ensure that the PowerShell script only requires a token, and not a login. We could of course do a login, but this way we can use the token for automation purposes later. Choose the type of authentication We can then search for the three permissions we need Machine.Read.All Software.Read.All Vulnerability.Read.All Once each of these permissions has been found, and checked, select add permissions at the bottom of the page. Once completed it will look like this, and you will need to then grant admin consent. Granting Admin Consent will pop up a box to confirm that you would like to grant these permissions. At this time the permissions are set now we just need to create a key! ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:2","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Creating a Key AKA a Secret First we will navigate to the certificates and secrets section. Next we can create a new client secret, note for improved security usage of a certificate is also recommended for identity validation. This will then open the Add a client secret window. Select a time frame for the secrets expiration. I would recommend no more than 12 months. And select Add. This will then generate the client secret ID and the value for the secret. Make sure you save this.. IMPORTANT: Once you leave this screen the value is hidden and cannot be recovered, securely store this value. Get your tokens That’s it the secret is now generated and now we can move on to testing! ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:3","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Validation A quick stroll back to part 1 to grab the script is all we need. We then plug in, the tenant ID, application ID, and the secret. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:4","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Vulnerability Management is hard.","date":"2021-01-28","objectID":"/posts/query-defender-for-endpoint-part-1/","tags":["PowerShell"],"title":"Query Defender for Endpoint Part 1","uri":"/posts/query-defender-for-endpoint-part-1/"},{"categories":["Security"],"content":"Vulnerability Management is HARD nderstanding patch compliance is mission critical task for all organizations regardless of their size or affiliation. What a lot of organizations struggle with is the different between vulnerabilities and patch compliance. As a result a lot of companies end up buying expensive third party tools to scan their environment for vulnerabilities, which happens to include your base Microsoft Patches. These vulnerability scans result in providing a huge sometimes seemingly unconquerable list for the IT department. Fortunately a large number of these vulnerabilities can be mitigated using a third party patch management solution like PatchMyPC. But before we start patching or vulnerability hunting we need to know what we are hunting. Fortunately the Defender ATP portal can make the initial vulnerability discovery easy. In this blog post the following items will be covered: Building an Authentication Token for Defender Querying the Defender for Endpoint API for vulnerabilities using PowerShell Turning that Data into a consumable CSV Report There will be future blog posts to cover the following: Creating a security key with minimal read permissions for the API Converting Vulnerability data into PowerBI Reports Querying the same data using KQL The above planned posts will be updated and linked as they are written. This blog post assumes you already have an app registration, and an API secret key in Azure AD – or have the knowledge to create one. If you do not – a new post on how to create one is scheduled for next week. ","date":"2021-01-28","objectID":"/posts/query-defender-for-endpoint-part-1/:1:0","tags":["PowerShell"],"title":"Query Defender for Endpoint Part 1","uri":"/posts/query-defender-for-endpoint-part-1/"},{"categories":["Security"],"content":"Asking the right Question Before we get into automation lets jump into how we can test out different API endpoints to find out what data we would get back. Whenever I do data analytics, or build a report the first thing I do is try to make sure I’m asking, and answering the right question. If you navigate with me to securitycenter.Microsoft.com we can find to query the endpoint API without any type of automation. This way we can ensure we have the right question before we waste a bunch of time on other things. Once you click on the API Explorer you’ll be taken to a webpage that showcase different ways you can query the defender API to retrieve data. I would encourage you to use the API Explorer to test different endpoints and see what data is sent back and how. While the overall documentation for the website is pretty good, it’s confusing especially if API’s are not something you play with on a regular basis. You can use these queries to get a good idea of how the API works simply click one of the samples, for this example I’m going to chose “get 10 Vulnerabilities by machines” and then click the “run query” button. Once you click the run query button if you have any machines with vulnerabilities in the environment you’ll get a return back! This alone gives us a bunch of data that’s useful. We know the CVE-ID we know the machine ID and we can use that to find the referenced machine we need to go patch. However, this format this style isn’t very helpful and having to log into a web portal like this is probably not something we can expect a manager to do on a daily basis. Fortunately we can take the URL – presented to us above and use it with PowerShell to automate the data grab, and make it present only the data we are interested in. For this we will be using the URL: https://api-us.securitycenter.windows.com/api/vulnerabilities/machinesVulnerabilities? ","date":"2021-01-28","objectID":"/posts/query-defender-for-endpoint-part-1/:2:0","tags":["PowerShell"],"title":"Query Defender for Endpoint Part 1","uri":"/posts/query-defender-for-endpoint-part-1/"},{"categories":["Security"],"content":"Asking the Right Question – With PowerShell PowerShell has a couple of different ways to query an API. However before we can even get started with querying the API we need to build our bearer token which will authenticate us to ASK questions. Fortunately this is pretty well documented on the Microsoft Website. This was theory, it's different in the real world NOTE: Everything above was theory and info, USE CAUTION on the lines below. When you query the API you could potentially pull sensitive (vulnerabilties) – information – and a LARGE amount of information. MAKE SURE YOU TEST before you drown your machine in data. $tenantId = '' ### Paste your tenant ID here $appId = '' ### Paste your Application ID here $appSecret = '' ### Paste your Application secret here #NOTE: Build the auth response token to the Windows Security Center API (Basically establishing a logged in session) $resourceAppIdUri = 'https://api.securitycenter.windows.com' $oAuthUri = \"https://login.windows.net/$TenantId/oauth2/token\" $authBody = [Ordered] @{ resource = \"$resourceAppIdUri\" client_id = \"$appId\" client_secret = \"$appSecret\" grant_type = 'client_credentials' } $authResponse = Invoke-RestMethod -Method Post -Uri $oAuthUri -Body $authBody -ErrorAction Stop #NOTE: This returns your access token, and below we pull out the token that will be used as the authorization token going forward. $token = $authResponse.access_token The above token object will then be used to query the API and get data back. Once we have the token (You can validate it by running $token in the command line) we can use a simple invoke command to get some data back and translate it from JSON. First we build our header. Note how we specific the content type, and the bearer token. $headers = @{ 'Content-Type' = 'application/json' Accept = 'application/json' Authorization = \"Bearer $token\" } Then we invoke the URL that we stole, I mean borrowed from the API Explorer. $url = \"https://api-us.securitycenter.windows.com/api/vulnerabilities/machinesVulnerabilities?\" $response = Invoke-WebRequest -Method Get -Uri $url -Headers $headers -ErrorAction Stop $Data = $response.Content | ConvertFrom-Json $Data.value Behold our vulnerabilities! – Now there are only a few more things we need to do here. Most managers won’t exactly approve of being handed an obscure “MachineID” as a way to start fixing issues. Fortunately the API has a way for us to retrieve that information as well. https://api-us.securitycenter.windows.com/api/machines The above uri will get us our machine information that means we can re-run our above code with one small change and we can get the data we want back! https://api-us.securitycenter.windows.com/api/machines The above uri will get us our machine information that means we can re-run our above code with one small change and we can get the data we want back! This will return back the ObjectID and the DNS name of the machine, then it’s just some matching games in PowerShell and we’ve got the vulnerabilities combined with useful information! An important NOTE: You could do all of this data analysis in PowerBI – and simply absorb the two outputs and skip this step. However if you just want a nifty CSV – this works great. $endingData = New-Object -TypeName System.Collections.Generic.List[PsObject] foreach($machine in $machineData.value){ $MachineVulnerabilitylist = $vulnerabilityData.value | Where-object {$_.MachineID -eq $machine.ID} foreach($vulnerability in $MachineVulnerabilitylist){ $machineDataHash = [ordered]@{ MachineName = $machine.computerDnsName MachineID = $machine.id lastSeen = $machine.lastSeen OSPlatform = $machine.osPlatform version = $machine.version agentVersion = $machine.agentVersion osBuild = $machine.osBuild isaadJoined = $machine.isAadJoined lastIpAddress = $machine.lastIpAddress lastExternalIpAddress = $machine.lastExternalIpAddress healthstatus = $machine.healthStatus CVE = $vulnerability.cveID productName = $vulnerability.productName productVendor = $vuln","date":"2021-01-28","objectID":"/posts/query-defender-for-endpoint-part-1/:3:0","tags":["PowerShell"],"title":"Query Defender for Endpoint Part 1","uri":"/posts/query-defender-for-endpoint-part-1/"},{"categories":[""],"content":"How to use Sir, to integrate with Microsoft ToDo","date":"2021-01-21","objectID":"/posts/to-do-with-siri/","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":[""],"content":"It’s just after the first of the year, and I’m sure those New Years resolutions are still burning in the background of everyone’s heads. What better way to accomplish those resolutions than using the tools we have available to us! Well, I tried to use Microsoft ToDo last year. I really did. I found whenever I was sitting in front of a computer I was very dilligent in it’s usage and accomplishing things. However, when wandering around I always found myself making excuses for not taking my phone out and using the app. Further complicated by having two different tenants. A personal one with the boss lady and one for work. With the introduction of “shortcuts” in iOS I decided enough was enough. I was going to remove “having to take out my phone” as an excuse. ","date":"2021-01-21","objectID":"/posts/to-do-with-siri/:0:0","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":[""],"content":"iOS Shortcuts Beginning in iOS 13 apple by default started adding an application called “Shortcuts”. The idea being apple wanted to provide an easy set of building blocks allowing users to create automated tasks and to help fill the gaps where Siri might fall short. Some of the cool things that the shortcuts app lets you do is build home automation for anything that integrates with the apple home kit as well. A great example is something like the ability to turn a set of lights on from your home screen without having to fuss with “Find the app, open the app, find the set of lights you want on, turn them on” and then repeat the process to turn them off. I don’t particularly enjoy that process and I imagine you don’t either. ","date":"2021-01-21","objectID":"/posts/to-do-with-siri/:1:0","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":[""],"content":"Shortcut Scripting Shortcuts are interesting in how you have different options to interact with Shortcuts. When you create a new Shortcut the first thing to know is the “Name” of the shortcut is the activation phrase so when you first create a shortcut like below, the activation phrase is “Hey Siri New Shortcut” that’s not very helpful but if you click the three dots you can change it to something useful. Lets set up a quick shortcut to get something done today that will optionally remind us! Here I’ve gone ahead and created a new task on the screen called “Make a New task” so when I say “Hey Siri, make a new task” it will launch this workflow. Next I need to get some further input, because for various reasons you can’t add a variably into the startup phrase. So if you select “add action” and then choose scripting You can scroll WAAAAAAAAAAAAAY down towards the bottom and find the ask for input option. This lets you get a prompt from Siri about what you want to do. So I’ve set a picture below and I’ve cheated a little bit because I’ve put two steps into one. First I’m accepting the input, and then I’m using another action to store the result of that input into a variable called “Task Name” I’ll cover that later. One of the big benefits to the TODO application is the ability to remind us when it’s time to work on a task. And with a little more scripting we can add a conditional to determine if this task should have a reminder set. To accomplish this, we first add another block to do a test to see “Should I remdind you to get this task done” and if the answer is YES we will capture a block of time on WHEN we should remind you. Side note, in this picture, you can change all the input types when you’re testing AND the conditionals. You can also set a default answer to look for. Once we are inside the if conditional we just need to use the same ask for input action to get a DATE TIME response this time, and then use it’s result to create a new task! NOTE when you search for tasks the “TO DO” app can execute search for “Microsoft” Searching for “toDo” often returns wrong apps. Below you can see a screen shot of what it looks like. Remember that variable I mentioned earlier? Here is where it comes back into play. You use it here to ensure the name of the task is properly passed through otherwise the name you gave it earlier is thrown away. What’s really neat about these simple building blocks is how once you understand them you can put them together to increase complexity as needed using different word queues. Maybe you need a more advanced todo with notes? Just add another shortcut with some more options and variables and a different word choice cue. Or maybe you just need something simple like updating the grocery list, no reminders no nothing you just are in the middle of cooking and can’t be bothered to wash your hands to grab your phone. I hope this was helpful as I know the first time I tried to build a shortcut not everything made sense the first time. I know this wasn’t very detailed but if you want to see more content like this or more in depth automations let me know in the comments! ","date":"2021-01-21","objectID":"/posts/to-do-with-siri/:2:0","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":["PowerShell"],"content":"Getting time is hard when it comes to code.","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"If you’ve ever worked in a large distributed environment you’ve likely experienced time issues. Maybe it’s not even so much an issue as you just want to know where the heck in the world a machine is. Especially in the current state of the world where almost every other day I wake up and go “WHAT YEAR IS IT” every day is Monday and everything is always on fire I’m sure you’re thinking can’t I just invoke command to it? Or maybe just enter PSSession? Well that’s what I thought too but in testing I got a mixed bag of results. ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:0:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"Enter-PSSession Get-Date For the purpose of this I have a test server: “PROBRESFS01” and my local machine “WARMACHINE”. One is in eastern time, and the other is in Pacific time. A slight difference. Now, one would assume that from here, I can run Get-Date and get the current time for PROBRESFS01. One would also be CORRECT in that assumption. This is because the sessions LOCALE information is sent across the session. However, that’s not really convenient if you need to get the time for a group of servers, say something like all distribution points in an environment. ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:1:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"Just use Invoke-Command then right? Well, kinda. Watch what happens when we use invoke command to get the current time. Huh, for some reason it’s now showing the time retrieved from the remote server in MY time. As best as I can tell, this is because PowerShell is trying to help you by converting the time back into something you can understand. When it does this it does it for your current timezone. ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:2:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"OK but then how? We can tackles this a couple of ways. The first option is just get the time zone information of the remote computer, and then convert your local machines time to it. However, that means if there is a difference in minutes between the two you won’t know about it. So what if we get both, and then convert it using .NET? $ComputerName = \"REMOTEPC\" $TimeZone = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-TimeZone} $Time = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-Date} $CurrentTime = [System.TimeZoneInfo]::ConvertTimeBySystemTimeZoneId(($Time), \"$($TimeZone.ID)\") $CurrentTime Well that’s a pretty good start. We can do better, what if we turn it into a function instead. function Get-RemoteTime { [CmdletBinding()] param( [Parameter(HelpMessage = \"The name of the remote computer\")] [string]$ComputerName ) #Get the timezone of the remote computer $TimeZone = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-TimeZone} #Get the Time of the remote computer $Time = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-Date} $CurrentTime = [System.TimeZoneInfo]::ConvertTimeBySystemTimeZoneId(($Time), \"$($TimeZone.ID)\") return \"The current time of the remote machine is: $($CurrentTime) it's TimeZone ID is: $($TimeZone.ID)\" } Get-RemoteTime -ComputerName \"RemotePCName\" Can we take it even further beyond? Of course we can lets get the time for all DPS: note if you have a CMG it will error on that one… Remote PowerShell to a cloud DP just sounds bad. function Get-DPCurrentTime{ [CmdletBinding()] param( [Parameter(HelpMessage = \"Enter the name of the ConfigMgr Server\",Mandatory = $true)] [string]$ConfigMgrServer, [Parameter(HelpMessage = \"Enter the ConfigMgr Site Server\", Mandatory = $true)] [string]$SiteCode ) begin{} process{ $DPList = Get-WmiObject -ComputerName $ConfigMgrServer -Namespace root\\sms\\site_$SiteCode -Query \"select distinct ServerName from sms_distributionpointInfo\" $List = [System.Collections.Generic.List[object]]::new() ForEach($Server in $DPList){ $TimeZone = Invoke-Command -ComputerName $Server.ServerName -ScriptBlock {Get-TimeZone} $CurrentTime = [System.TimeZoneInfo]::ConvertTimeBySystemTimeZoneId((Get-Date), \"$($TimeZone.ID)\") $Hash = [ordered]@{ ServerName = $Server.SERVERNAME CurrentTime = $Currenttime TimeZone = $TimeZone.DisplayName } $Item = New-Object -TypeName PSobject -Property $Hash $List.Add($Item) } return $List } } https://github.com/JordanTheITGuy/PowerShell/blob/master/BlogPosts/HowTo%20-%20Get%20Local%20Time%20for%20All%20DPS/Get-LocalTimeDPS.ps1 ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:3:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":null,"content":"A short personal story about the Digital Divide and it's impact on the world.","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"The Digital Divde in Rural America is more than just a news story This blog post has been a long time coming. I feel an obligation here to inform any regular readers I have if you are expecting a technology post, this isn’t it. One additional warning, this post will get a little bit into my personal life story. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:0:0","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Some important history To understand how I ended up in the spot I’m in today there are some key things to know about my past. First, my parents got divorced when I was five. OK, nothing really interesting, happens all the time. What happens less often is your mother dying in a car crash with no last will and testament when you’re nine. Now you’re wondering how this is relevant. When a couple who has a child is divorced has no will, all of their possessions are passed on to the children, or in this case me. This included a house I started making payments on as a nine year old. Well, I didn’t but my father did as my Probate Court appointed representative. If you’re keeping score at home, I was born in 1990 – and started making house payments in 1999. This will come up later… ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:1:0","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"The beginning of the sad times with no internet “ish” Back in 2016, I lived in an apartment in the Greater Detroit area. I also started a job working for a company allowing full remote work. Things were awesome. However, within a month or two, my grandmother passed away. My grandmother 98 at the time, had been living in my house back in my home town of Hillsdale. When she passed, I suddenly had a remote job, a house, AND an apartment. Combine all these changes with how my roommate was preparing to move out to live with his now fiancé and it was time to make some decisions. I decided to move home to my small town and start working on making my house nice. I figured worst case scenario I could always use the internet at my dads shop. TLDR: My roommate in Detroit was moving out, I had an empty house in my home town, my mortgage was cheaper than any apartment I could ever get. So why pay for an apartment? ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:1:1","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Internet Options Getting ready to move back to my home town I started looking at different internet options and I was really excited! A quick glance indicated how things had changed since I left. I even saw some broadband choices. I soon learned this was a lie. What internet providers don’t tell you is how the coverage maps including the ones provided by the FCC are NOT a comprehensive picture. The way the coverage maps work basically are if any one house inside of a CENSUS block, has broadband the ISP can claim they provide coverage to the entire CENSUS block. Here is an example of a Census block where because people live on lakefront property an ISP brought a physical connection to them, one mile away from me and as a result if you navigate to the FCC website it claims everyone here has access to the following speeds from these providers. When in reality: And before people go about yelling “Oh you doxed yourself” – I’m not hiding where I live is literally government public record. I’m not hard to find. Now the inevitable answer to this is always “Oh just have cable brought to your house”. Well, of the different providers I tried to reach over the years I only ever got a response from ONE. Let me tell you their response was perfectly reasonable… The number pictured didn’t change for four years. Which brings me full circle on why PROPER reporting of where internet access specifically BROADBAND access is available in the USA is so important. The map above claims I have internet is responsible for deciding what companies get what funds. My CENSUS block, was considered NOT eligible for funding in the Connect America Phase II act. Additionally, Frontier Communications – The ONLY company with a physical hardline to my house (only capable of providing .5 – yes .5 not 5) – received $725K went bankrupt this year. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:0","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Give me Options Captain By now you’re going, why haven’t you moved, sold your house run off and joined a circus, something anything to get back to even second world internet. Well, the answer lies up above. I started making house payments when I was 9 years old. I’m now 30. 21 years of house payments. Consider the average duration of a mortgage and you have an idea of why I might not want to move. Sell my house, losing my equity, and move somewhere else. (Higher monthly cost of living, but hey internet). Use LTE Service for Internet Drive to Town and use the internet at my dad’s shop Try to find a way to trench cable through a mile of land for home internet. I tried using an ATT LTE service for a while, unfortunately (and it doesn’t matter which carrier you pick) it only sometimes worked. I mean if you call this working then I guess… On RARE occasions it might even consistently run like this: So you could technically say I had “internet” at my house for the four years I’ve lived here. Sure technically. If you consider the above – adequate internet service for an IT professional. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:1","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"OK but how did you work? Fortunately this is my home town. My dad, has owned and operated his own store since 1984 here in Hillsdale MI. He was kind enough to let me build an 8×8 office on his premises and use his internet and electricity in exchange for supporting his… less than modern equipment. This meant for me any time I needed to do anything other than maybe watch some Netflix on my phone, I had to drive the 15 minute journey to the office. As a nerd and video game lover this led to me spending almost no time at my house at all for four years. I came home to eat, sleep and play with my dogs. The rest of the time I essentially lived in town in my office. Sometimes I even brought the dogs with me. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:2","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Enter “Barad-Dûr” or “The Tower” Prior to me moving back to “the dale” there was one other option available to me. However the trees had grown to a point where it wasn’t feasible to use. The last option was a local Point to point wireless company called DMCI Broadband. http://dmcibb.net/ Yes, I know the 90’s called they want their website back but don’t hate. The company recently started offering the ability to build a tower for you in your own backyard. So I called them, and low and behold, they could finally bring speeds up to 20mb/s to my area with a promise of 100mb/s later this year. Unfortunately in order to make it work I had to be able to clear the tree line so I could hit their radio tower: TWO MILES AWAY So, after some investigation with a bucket truck and a drone. We found we could reach their tower we started building it. It’s hard to realize how tall it is without the light fixture but 80 feet is REALLY high.. like 6-7 story building tall. The below speed test was taken this evening, the VP of the website was playing a video game next to me. The tower pictured above finally advanced the internet connection here at home past the age of the late 90’s. While the speed is not a consistent 20mbps at all, I will say the latency has been ROCK solid. Especially knowing they are increasing capacity later this month. I hope this was helpful in explaining, and I also hope no one else ever has to go through this. Additionally I hope it opens some eyes to just how disconnected Rural America STILL is. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:3","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":["ConfigMgr","SQL"],"content":"Direct Membership rules are frequently a topic for debate due to performance and other reasons. This post will show you how to find them!","date":"2020-08-17","objectID":"/posts/find-direct-membership-collections/","tags":["SQL","ConfigMgr"],"title":"Find Direct Membership Collections","uri":"/posts/find-direct-membership-collections/"},{"categories":["ConfigMgr","SQL"],"content":"Direct Membership rules are frequently a topic for debate due to performance, and other challenges. However, if you work in an environment where you share Configuration Manager with several other admins you might not know just how many collections you have with direct memberships, or where they are. ","date":"2020-08-17","objectID":"/posts/find-direct-membership-collections/:0:0","tags":["SQL","ConfigMgr"],"title":"Find Direct Membership Collections","uri":"/posts/find-direct-membership-collections/"},{"categories":["ConfigMgr","SQL"],"content":"SQL Query SQL, something most configuration admins are uncomfortable with for some reason or another. In this particular case is probably the fastest and most direct method of acquiring the information you want. If all you want is to know what collections have direct membership rules you can start just by selecting: SELECT * FROM V_CollectionRuleDirect This will get you all of the direct membership collection rules in an environment. A couple things to note here, we are provided the CollectionID, where the rule is attached, the NAME of the rule, the RESOURCEID indicated by the rule, and the resource type. The rule name, and resource type are worth paying special attention to for a few reasons. ","date":"2020-08-17","objectID":"/posts/find-direct-membership-collections/:1:0","tags":["SQL","ConfigMgr"],"title":"Find Direct Membership Collections","uri":"/posts/find-direct-membership-collections/"},{"categories":["ConfigMgr","SQL"],"content":"Rule Names When a direct membership is created using a DEVICE – or resource type 5 more on that later – the devices NAME is used as the rule name, and it’s resourceID is whats used in the queries actual language. This is part of why direct memberships are so contentious. As when a machine is re-imaged it may have a different resource ID, causing the rule to lose all purpose and meaning. ","date":"2020-08-17","objectID":"/posts/find-direct-membership-collections/:1:1","tags":["SQL","ConfigMgr"],"title":"Find Direct Membership Collections","uri":"/posts/find-direct-membership-collections/"},{"categories":["ConfigMgr","SQL"],"content":"ResourceType In the example above I have a USER based collection called “App-Minecraft” that I am using to deploy Minecraft to users who are a member of a group. It’s important to note GROUPS show up as direct memberships as well and do NOT suffer the same complications as direct membership device rules. If you’re wondering how I know that resource type 3 is user group, and 5 is system you can use the below query to find out the mapping of ResourceType to its display Name, and its class name view in the database. SELECT * FROM v_ResourceMap ","date":"2020-08-17","objectID":"/posts/find-direct-membership-collections/:1:2","tags":["SQL","ConfigMgr"],"title":"Find Direct Membership Collections","uri":"/posts/find-direct-membership-collections/"},{"categories":["ConfigMgr","SQL"],"content":"Stop Talking give me the Query With those little bits of information in hand we can easily create a very simple query using the COUNT, GROUP BY, and WHERE to find and sort our collections with direct memberships that are dictated by DEVICES. SELECT V_CollectionRuleDirect.CollectionID as 'CollectionID' , COUNT (V_CollectionRuleDirect.CollectionID) AS 'TOTAL' FROM v_CollectionRuleDirect WHERE v_CollectionRuleDirect.ResourceType = '5' GROUP BY v_CollectionRuleDirect.CollectionID ORDER BY TOTAL DESC However, with a little more nudging around we can add in the collections name to make it easier to find. SELECT V_CollectionRuleDirect.CollectionID as 'CollectionID' , V_Collections.CollectionName as 'Collection Name' , COUNT (V_CollectionRuleDirect.CollectionID) AS 'TOTAL' FROM v_CollectionRuleDirect LEFT OUTER JOIN v_Collections on V_Collections.SiteID = v_CollectionRuleDirect.CollectionID WHERE v_CollectionRuleDirect.ResourceType = '5' GROUP BY v_CollectionRuleDirect.CollectionID , V_Collections.CollectionName ORDER BY TOTAL DESC ","date":"2020-08-17","objectID":"/posts/find-direct-membership-collections/:2:0","tags":["SQL","ConfigMgr"],"title":"Find Direct Membership Collections","uri":"/posts/find-direct-membership-collections/"},{"categories":["ConfigMgr"],"content":"It’s the moment we’ve all been waiting for! In response to this little feedback feature from one Steven Owen – now an employee at Microsoft: https://configurationmanager.uservoice.com/forums/300492/suggestions/20509528 Microsoft has added the long awaited community hub and now it’s more than just the documentation! In fact you’ll soon be able to submit your own features to it! We're VERY close to opening the doors broadly to the Community hub. Question for all you #ConfigMgr admin's: What type of safeguards and gates should we put in front of the community? Tell us what you think! — Mark Silvey (@configmgrdev) August 12, 2020 ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:0:0","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["ConfigMgr"],"content":"Requirements There are some requirements that need to be met before the Community Hub component can be leveraged. Some of them are kinda weird so bear with me: ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:1:0","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["ConfigMgr"],"content":"You MUST connect from a WINDOWS 10 Machine I know Server 2016/19 is kind of like windows 10 but in this case it’s NOT the same. If you you try to use the Primary Site Server you WILL receive an error. ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:1:1","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["ConfigMgr"],"content":"You MUST have .NET 4.6 OR Higher installed. NOTE: After this blog was posted Mark Silvey Replied and explained WHY these requirements currently exist Great write up on the hub Couple notes: 1. browser control in use causes the w10 \u0026 .net requirements. Hope to fix in 2010 2. admin service is on and working by default in 2006 so this should just work without those changes https://t.co/OJfmDYZ4Yz — Mark Silvey (@configmgrdev) August 14, 2020 If you don’t meet the above requirements you will get the following error. ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:1:2","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["ConfigMgr"],"content":"The logged in users CANNOT be the built-in administrator account I feel there is a story behind this one. I didn’t test this scenario so I can’t show you what the behavior on it is short of it might crash. I’m honestly unsure, however I am optimistic no one is using configuration manager and only using a local admin account. ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:1:3","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["ConfigMgr"],"content":"Unable to access Community hub node when running console as a different user If you’re signed in as a user with lower rights and choose Run as a different user to open the Configuration Manager console, you may not be able to access the Community hub node. This one I can show you the behavior for because I don’t typically log into my machine as my ConfigMgr admin account. This is a common result if you use the “run as” command. Having seen something similar to this before with trying to use configuration manager from a non-domain joined machine. So I tried this and it seemed to work but as far as I know it’s not supported. PS C:\\Users\\jbenz001\u003e runas /netonly /user:DOMAIN\\USERNAME \"C:\\Program Files (x86)\\Microsoft Configuration Manager\\AdminConsole\\bin\\Microsoft.ConfigurationManagement.exe\" ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:1:4","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["ConfigMgr"],"content":"The administration service in Configuration Manager needs to be set up and functional. The last one is the big one. You need to make sure you have the Administration Service enabled. This includes ensuring the checkbox for the hierarchy is checked see the below image. If you have an environment that does NOT have a PKI infrastructure. You may face some additional challenges. The below message is one example. If you experience this and are you using EHTTPS, you need to import the SMS Issuing certificate into your Trusted Root store. You can do this by opening the configuration manager console, navigating to: Administration -\u003e Security -\u003e Certificates. Select the currently ACTIVE certificate for SMS Issuing, right click and view its properties. Then select to install the certificate in the trusted root store for the computer. ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:1:5","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["ConfigMgr"],"content":"Enough Requirements Show Me the goods! So once you’ve finally got all your requirements done. Here’s what it looks like! You’ll want to get logged into GitHub by clicking the login item in the top panel. When you do this you WILL be prompted for MFA if you have it configured – I hope you do…and for permission to generate an OAUTH token. The current Icons are a little confusing as to what is what so here’s a quick clarifying screenshot. Remember if you pull in a script, you will still need to APPROVE it before it can be used in your environment. For example lets say we wanted the Query Windows Power Plan Per Device script. Click the item which will then provide you with the “Download” option. Make sure you have the appropriate permissions to create a script in the environment otherwise you’ll get yelled at. This will then generate the script in your console. Finally if you ever try to download an item and it can’t create the object you can always click “View Source” and it will take you to the GitHub page and you can see source contents to copy for yourself! Hopefully this helps you out with getting started. ","date":"2020-08-14","objectID":"/posts/memcm-community-hub-getting-started/:2:0","tags":["ConfigMgr"],"title":"MEMCM   Community Hub Getting Started","uri":"/posts/memcm-community-hub-getting-started/"},{"categories":["PowerShell"],"content":"I was recently asked to implement LAPS for a customer. Nothing unusual there. This particular environment was new to me which meant it was time to investigate their OU structure. When investigating, I learned that sometimes, PowerShell performance is weird.","date":"2020-08-10","objectID":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/","tags":["PowerShell"],"title":"Finding OU's With Workstations - PowerShell Performance Is Weird","uri":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/"},{"categories":["PowerShell"],"content":"I was recently asked to implement LAPS for a customer. Nothing unusual there. This particular environment was new to me which meant it was time to investigate their OU structure. ","date":"2020-08-10","objectID":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/:0:0","tags":["PowerShell"],"title":"Finding OU's With Workstations - PowerShell Performance Is Weird","uri":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/"},{"categories":["PowerShell"],"content":"Why does OU structure matter? When implementing laps there are a few things to keep in mind. First, you need to extend the schema. Then you need to grant computers permission to access the newly created attributes… Well to accomplish this you need to assign the self permission in your root computers OU but are you sure you got them all? What if you’re a global company and break down your computers and users into country OU’s? So how do we find all of the OU’s that have workstations in them? ","date":"2020-08-10","objectID":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/:1:0","tags":["PowerShell"],"title":"Finding OU's With Workstations - PowerShell Performance Is Weird","uri":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/"},{"categories":["PowerShell"],"content":"Enter PowerShell Gathering information from Active Directory can range from very simple to very complicated. Fortunately for us, we just want to know what OU all computer objects, with a workstation OS can be found in. This should be a relatively simple proposition. Get-ADComputer -Identity WARMACHINE Quick look and we find that we have the distinguished name property but it includes the name. Hrm. OK we can solve that right all we need to do is find the first ‘,’ and absorb the rest right? Well, here is where PowerShell and its associated methodologies gets weird. Get-ADComputer -filter * | ForEach-Object{$_.DistinguishedName.Substring($_.IndexOf(',') +1)} Get-ADComputer -filter * | Select-object DistinguishedName | ForEach-Object{$_.Substring($_.IndexOf(',') +1)} $(Get-ADComputer -filter *).DistinguishedName | ForEach-Object{$_.Substring($_.IndexOf(',') +1)} You would expect that all three of the above commands should return the same results. Not so much. The first two versions will fail spectacularly because the parser retains the object type information of the “DistinguishedName” attribute. However, the third one enters the property, expanding it and returning its string value. Simple tweak, and we can get only WORKSTATIONS instead. $(Get-ADComputer -filter 'OperatingSystem -notlike \"Windows server*\"').DistinguishedName | ForEach-Object{$_.Substring($_.IndexOf(',') +1)} Which will return some nice shiny results like this: Simple, direct and using only methods in the native pipeline. However, it’s not the only method of getting this done. I shared my solution with some friends in the WinAdmins Discord server because man substring and index of is pretty ugly but it works and I was curious what other peoples 5 minutes or less solution would be. ","date":"2020-08-10","objectID":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/:2:0","tags":["PowerShell"],"title":"Finding OU's With Workstations - PowerShell Performance Is Weird","uri":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/"},{"categories":["PowerShell"],"content":"Enter the Hash Splat Chris Dent, as soon as he saw the code went right to using the splat methodology: Get-ADOrganizationalUnit -Filter * | Where-Object { $params = @{ Filter = 'operatingSystem -notlike \"*server*\"' SearchBase = $_.DistinguishedName SearchScope = 'OneLevel' ResultSetSize = 1 } Get-ADComputer @params } Typically using where-Object and trying to limit specific properties using a splat SHOULD optimize the search and make it run significantly faster especially as machine counts scale. However, what I found after testing was interesting. I made an assumption that in the case of my lab the foreach statement would be more performant and no surprise – it was in fact almost 50% more efficient. Now, I assumed that we would start to see some performance gains at around 100 machines. So I did another test against about 600 devices, with 400 or so workstations. Don’t mind the red… I just can’t spell count. Holy cow, ForEach-Object was MORE efficient in this use case. So I went a few steps further in larger and larger sites, and it seems that around 4K devices is the magic number where suddenly a SPLAT method becomes more efficient but even then its only barely. ","date":"2020-08-10","objectID":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/:3:0","tags":["PowerShell"],"title":"Finding OU's With Workstations - PowerShell Performance Is Weird","uri":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/"},{"categories":["PowerShell"],"content":"What about using .NET Not one to be out done, another friend Cody Mathis was now curious. What if we used .NET: Measure-Command { $AllWorkstationSearcher = [System.DirectoryServices.DirectorySearcher]::new('(\u0026(!(OperatingSystem=Microsoft Windows *Server*)(objectCategory=computer)))', @('distinguishedName'), [System.DirectoryServices.SearchScope]::Subtree) $AllWorkstationSearcher.PageSize = 1000 $AllWorkstations = $AllWorkstationSearcher.FindAll() $OUsWithWorkstations = $(foreach ($d in $AllWorkstations) { ($d.properties['distinguishedName'][0] -replace '^[^,]+,') }) | Select-Object -Unique } This example was particularly interesting, because with the Double Wild card around “server” it performed consistently WORSE than both of the other methods used. However, when only a single wildcard was used (which generates the same results). It absolutely stomped the other two methods used. ","date":"2020-08-10","objectID":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/:4:0","tags":["PowerShell"],"title":"Finding OU's With Workstations - PowerShell Performance Is Weird","uri":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/"},{"categories":["PowerShell"],"content":"OK So what was the point of this again? PowerShell performance is almost always a subject for hot debate. Especially when you get into discussions around it with experts. This particular example use case study just happened to really highlight how depending on what method you use to retrieve data you can experience rather drastically different types of performance hits. The big thing to remember is to code for YOUR environment. A lot of the great PowerShell writers out there are used to writing code AT SCALE. That means they write things optimized for dealing with 50 – 200K objects when interacting with Active Directory. That means their code may not be the right fit for YOUR organization. Happy scripting! ","date":"2020-08-10","objectID":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/:5:0","tags":["PowerShell"],"title":"Finding OU's With Workstations - PowerShell Performance Is Weird","uri":"/posts/finding-ous-with-workstations-powershell-performance-is-weird/"},{"categories":["LifeStyle"],"content":"With social distancing people are looking for reliable and simple way to connect with friends and family. For many the “gaming” platform Discord has become their way to connect. Discord while incredibly easy to set up, especially compared to its former competitors Ventrillo and Teamspeak, is not always intuitive for first time users.","date":"2020-06-15","objectID":"/posts/discord-tips-and-tricks/","tags":["LifeStyle"],"title":"Discord Tips and Tricks","uri":"/posts/discord-tips-and-tricks/"},{"categories":["LifeStyle"],"content":"With social distancing people are looking for reliable and simple way to connect with friends and family. For many the “gaming” platform Discord has become their way to connect. Discord while incredibly easy to set up, especially compared to its former competitors Ventrillo and Teamspeak, is not always intuitive for first time users. Now, as some of my readers know I’m an administrator over at the WinAdmins discord. A community with a focus on professional development that also acts as a gateway for IT professionals to stay in contact between conferences you can join it here but finish reading before you do. ","date":"2020-06-15","objectID":"/posts/discord-tips-and-tricks/:0:0","tags":["LifeStyle"],"title":"Discord Tips and Tricks","uri":"/posts/discord-tips-and-tricks/"},{"categories":["LifeStyle"],"content":"Notifications First lets talk about notifications. When you first join a server depending on how it’s been set up you might get a TON of notifications. So it’s good to be aware of the options that are available to turn on and off. First there are – Server Notifications – for the entire server and then there are channel specific notifications. Youi can access the server specific notifications by right clicking the server in question and then selecting notification settings. This then allows you to help avoid alert fatigue and only get notifications for certain “tags”. Tags work the same way as on twitter or in Office365. Using an @ and a user name or ROLE. Discord however doesn’t stop there as it understands in servers with large communities there may be specific channels you wish to get notifications and others you don’t ever want to see anything. For those channels you can use the mute option for the channel. ","date":"2020-06-15","objectID":"/posts/discord-tips-and-tricks/:1:0","tags":["LifeStyle"],"title":"Discord Tips and Tricks","uri":"/posts/discord-tips-and-tricks/"},{"categories":["LifeStyle"],"content":"Voice Chat Of the many neat features for Discord is voice chat! Most servers will have a few different voice channels that people can participate in. Some will even have the option set up for video cameras. One thing to be very aware of is you join a voice channel by clicking it. Once you connect it’s not “obvious” how to disconnect. However there is a button at the bottom for both the app and the website version that you need to click to disconnect. You can also click the button to the left to enable the “KRISP” beta functioning which acts as software based noise cancelling. On other set of options you need to know about is directly below this which allow you to, enable your camera, share your screen, mute yourself and “Deafen” yourself. 1: Mute – Self-Explanatory it prevents sound from being picked up by your microphone and sent. 2: Deafen: Automatically mutes you and makes it so you can’t hear what’s happening in the channel you are in. Useful if you are in multiple calls on PC or need to hear the kids down the hall. 3: Settings: – This takes you to the settings panel for discord specifically the audio settings panel to ensure you have the right hardware set to use. 4: Video: Turns on your video camera so that everyone in the call can see you. 5: Screen: Turns on screen share, for a selected screen or application. 6: Disconnect: – Removes you from the currently connected voice chat. 7: Krisp – Enables the configuration of the noise cancelling software. Discord is a growing platform in fact it’s growing so much there is a Microsoft Discord server (not official but VERY large with a high number of Microsoft employee’s present) where they get involved with the community Check it out! https://discord.gg/microsoft If you want more tips and tricks about using Discord or how Bots work with discord let me know and I’ll put up some more content around how to get started. ","date":"2020-06-15","objectID":"/posts/discord-tips-and-tricks/:2:0","tags":["LifeStyle"],"title":"Discord Tips and Tricks","uri":"/posts/discord-tips-and-tricks/"},{"categories":["PowerShell"],"content":"Sometimes copy paste is just really hard. If you’ve ever found yourself working through multiple RDP sessions you’ve probably attempted to copy or paste something in a PowerShell session only to have it fail horribly. Maybe you’ve been trying to look at some returned data only to have it output in some weird list.","date":"2020-06-08","objectID":"/posts/powershell-copy-to-clipboard/","tags":["PowerShell"],"title":"PowerShell Copy to Clipboard","uri":"/posts/powershell-copy-to-clipboard/"},{"categories":["PowerShell"],"content":"Sometimes copy paste is just really hard. If you’ve ever found yourself working through multiple RDP sessions you’ve probably attempted to copy or paste something in a PowerShell session only to have it fail horribly. Maybe you’ve been trying to look at some returned data only to have it output in some weird list. ","date":"2020-06-08","objectID":"/posts/powershell-copy-to-clipboard/:0:0","tags":["PowerShell"],"title":"PowerShell Copy to Clipboard","uri":"/posts/powershell-copy-to-clipboard/"},{"categories":["PowerShell"],"content":"CLIP Struggling to copy the results of a PowerShell command to your clipboard so you can make a note? Rather than highlight the result and try to figure out how to copy based on which editor you are using. Instead just pipe the result to CLIP. Microsoft last updated the documentation for the clip command in 2017. Essentially it lets you redirect output to the windows clipboard. This enables you to do all kinds of things like. Get-ChildItem | Select-Object FullName | Clip Which would get all of the child items in a directory, select their full name and then copy the output to your clipboard. You can of course do this with just about anything that goes through the pipeline. To read more about how clip works check out the Microsoft docs site! https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/clip Some great uses for this might include when you are trying to diagnose an error message! Pretty neat right? What if we wanted to take this a step forward. Sometimes when you are first writing some code you might be testing out and re-running a a few try catch loops over and over and capture any errors in your clipboard so you can search for why something failed. Just a little tweaking and no problem! I’m sure there are tons of other ways you can use this in day to day coding! For me it’s a nice saving grace when I’m working through a web browser session and maybe I can’t use Ctrl+c or other options. If you think of anything that works well feel free to comment down below! ","date":"2020-06-08","objectID":"/posts/powershell-copy-to-clipboard/:1:0","tags":["PowerShell"],"title":"PowerShell Copy to Clipboard","uri":"/posts/powershell-copy-to-clipboard/"},{"categories":["ConfigMgr"],"content":"Something I like to do when building a new configuration manager environment is to create and deploy an admin tool box.","date":"2020-03-27","objectID":"/posts/configmgr-1910-user-policy-for-multiple-user-sessions/","tags":["ConfigMgr"],"title":"ConfigMgr - 1910 User Policy for Multiple User Sessions","uri":"/posts/configmgr-1910-user-policy-for-multiple-user-sessions/"},{"categories":["ConfigMgr"],"content":"Making things nice for your friends Something I like to do when building a new configuration manager environment is to create and deploy an admin tool box. This is especially easy when you have tools like PatchMyPC as you can pre-package certain applications like SQL Management studio using the enterprise plus subscription features. When I do this I’m usually not the only consumer of this toolbox, and it’s usually needed on different workstations and servers by various admins in my team. This allows me to do cool things like – make 7zip available to install on servers to ONLY the admin account of my team mates. ","date":"2020-03-27","objectID":"/posts/configmgr-1910-user-policy-for-multiple-user-sessions/:1:0","tags":["ConfigMgr"],"title":"ConfigMgr - 1910 User Policy for Multiple User Sessions","uri":"/posts/configmgr-1910-user-policy-for-multiple-user-sessions/"},{"categories":["ConfigMgr"],"content":"Servers - Recent Change In the past it’s been not “supported” to use user based deployments for multi session endpoints. It has worked, but depends on number of users and who has slot 0 in the session. Starting in 1910 the ConfigMgr team has added new functionality for user based policy. Now your MGMT server (which is almost guaranteed to have multiple users) supports the ability to have user based policy! What’s important to know about this is that the setting is disabled by default, This means if you previously had user based deployments that were working – (supported or not) – they may now fail with error code 0x0 until you change this setting. You can read the details about this setting here: https://docs.microsoft.com/en-us/configmgr/core/clients/deploy/about-client-settings#enable-user-policy-for-multiple-user-sessions Be aware that this setting could cause performance impacts! Happy deploying! ","date":"2020-03-27","objectID":"/posts/configmgr-1910-user-policy-for-multiple-user-sessions/:2:0","tags":["ConfigMgr"],"title":"ConfigMgr - 1910 User Policy for Multiple User Sessions","uri":"/posts/configmgr-1910-user-policy-for-multiple-user-sessions/"},{"categories":null,"content":"I have no idea what I am doing...","date":"2016-02-11","objectID":"/posts/adding-email-property-in-ad/","tags":null,"title":"Adding E-Mail Property in AD","uri":"/posts/adding-email-property-in-ad/"},{"categories":null,"content":"A few months back I worked on a project to configure a password manager that was managing accounts across multiple domains without a trust. The Problem: This password management software was actually pretty cool. It’s able to match user accounts in its secure data base using a particular active directory attribute. In this case the e-mail field. Unfortunately, the users with accounts in both domains didn’t have the same e-mail attribute. In fact the resource domain for production has no e-mail address’s assigned to it almost at all. The Solution: The solution here was actually a fairly simple set of powershell code that did a few things. First, I imported a CSV file using a relationship of UserName and E-MAIL account. (Which I extracted from the primary domain you know the one where they actually HAVE the correct information) . Then using that data I read through all users that exist in the list and if I found the user, then I checked to see if they had an e-mail address. If they did I logged it and didn’t make a change. If they did NOT have an e-mail address I went ahead and gave them the correct e-mail address. It looked something like this: $DataPath = Read-Host \"Enter The file name or path here\" $AllUserData = Import-CSV $DataPath Import-Module ActiveDirectory ForEach ($User in $AllUserData){ $UserADObj = Get-ADUser -Identity $User.username -Properties Mail If ($UserADObj.mail){ $Output = \"User \" + $User.Username + \" already has an email set of \" + $UserADObj.Mail Add-Content C:\\PowershellLogs\\EMailAddressErrorLog.txt $Output } Else{ Set-ADUser $User.Username -EmailAddress $User.EMailAddress } } ","date":"2016-02-11","objectID":"/posts/adding-email-property-in-ad/:0:0","tags":null,"title":"Adding E-Mail Property in AD","uri":"/posts/adding-email-property-in-ad/"},{"categories":["Active Directory"],"content":"What in the world are protected groups in Active Directory?","date":"2015-11-03","objectID":"/posts/protected-groups-in-active-directory/","tags":["Research"],"title":"Protected Groups in Active Directory","uri":"/posts/protected-groups-in-active-directory/"},{"categories":["Active Directory"],"content":"The Question: This morning we hired a new and wonderful guy for our Help-desk and when setting up this persons account a strange oddity occured that caused one of the other helpdesk workers to come over to me and ask, “Hey why can’t I reset this new guys account? I can reset anyone else’s account but not his”. Now, I’m not proud I’ll admit at first I was stumped on this one there shouldn’t be any reason why you can’t reset his account I said – Mildly grumpy having only had one cup of coffee so far that day – Show me what you mean! Sure enough after walking over to his desk I watched him crack open AD Users and Computers and he couldn’t reset the guys password. The Assumptions: During this initial observation I made several assumptions and in order for this scenario to make sense some more information is required. This Organization does NOT use elevated accounts. It’s written in the standards document but the document hasn’t been ratified and implemented yet. The Organization DOES use delegated rights over accounts to allow certain users to be able to reset accounts that are a part of a single OU. The User attempting the modification is a member of a group that has been delegated those rights. The User who is being modified is in an OU that the other user has delegated rights over. The Problem: In a NORMAL use case scenario this wouldn’t have come up this particular challenge arose from a specific set of circumstances. The user we were attempting to modify (We’ll call him the User) and the user doing the modifying (We’ll call him the Admin for now) was created in a DIFFERENT OU than his final resting place, and prior to being moved there he was added to a security group that was NESTED in one of the Active Directory Protected Groups. What you ask, is an active Directory Protected Group? Well let’s start by listing what they are from the Microsoft Technet Website: So, what does this actually mean? Well when a user account is added to one of the protected groups a few things happen. For starters every hour Active Directory starts this wonderful process that looks at users that are a member of these protected groups. Then upon finding those members it reaches out and sets the AD attribute “AdminCount” to the value of 1. This signifies to ActiveDirectory that this account is an “Administrative” account and to disable inheritance on the object and to enforce the security of AdminSDHolder. The Resolution: Fortunately in this case the simple solution to achieve the desired behavior in this environment was “acceptable”. However, it doesn’t solve the problem as a whole. The simple one off solution is using active directory users and computers from a domain administrator account enable inheritance on the user object. This will allow the appropriate inherited permissions to flow down on to the user before locking the account again from being edited by delegation on OU’s. This however, is NOT a long term solution. The correct LONG term solution would be to create an elevated account for ANY user that NEEDS to be a member of a protected group and place them in a dedicated OU in accordance with Microsoft best practices. Currently in development here at problem resolution is a script that will regress through a users security groups and list the protected group the user is a member of as well as the group path that provided that membership. So, what does this actually mean? Well when a user account is added to one of the protected groups a few things happen. For starters every hour Active Directory starts this wonderful process that looks at users that are a member of these protected groups. Then upon finding those members it reaches out and sets the AD attribute “AdminCount” to the value of 1. This signifies to ActiveDirectory that this account is an “Administrative” account and to disable inheritance on the object and to enforce the security of AdminSDHolder. DANGER: READ THIS This post is very old and likely has outdated information in it ","date":"2015-11-03","objectID":"/posts/protected-groups-in-active-directory/:0:0","tags":["Research"],"title":"Protected Groups in Active Directory","uri":"/posts/protected-groups-in-active-directory/"},{"categories":["PowerShell"],"content":"Every now and again there comes a need to get the members of a group and manipulate that data in some fashion.","date":"2015-10-30","objectID":"/posts/powershell_get_members_of_group/","tags":["PowerShell"],"title":"PowerShell Get Members Of Group","uri":"/posts/powershell_get_members_of_group/"},{"categories":["PowerShell"],"content":"Every now and again there comes a need to get the members of a group and manipulate that data in some fashion. Now there are many ways to skin this cat and work with this data from VBscript, to utilizing DSquery to Quest Powershell CMDLETS to just raw powershell cmdlets. Rather than spend time writing a new script every time you work at a different place or having to change constants in a script I spent some time writing a quick powershell script that accepts some variable information an outputs a CSV, or TXT file (your choice) with the user’s SAMaccountName combined with first and last name for all members of that group. You can copy and download a version of the PS1 Script from Here to make sure there are no white space errors. ########################################################################## # Powershell Written by Jordan Benzing # # Last edited on 10/30/2015 # # Version 1.0.0 # # Disclaimer: This is provided as is and gaurantees no support # # Just because this script works in my environment does not mean it will # # always work in your environment. Please perform appropriate testing for# # your environment. # # Any updates will be hosted at problemresolution.wordpress.com # # # ########################################################################## $GroupName = Read-Host \"Enter the name of your group here\" $DomainName = Read-Host \"Enter the Domain you are querying here\" $SaveFile = Read-Host \"Where would you like to save the output? Example: C:\\users\\Username\\Desktop\\test.csv\" $MembersofGroup = Get-ADGroupMember -Identity $GroupName $AllUsers = {$TheUsers}.Invoke() ForEach ($Member in $MembersofGroup){ $CurrentUser = $Member.SamAccountName $CurrentUser = Get-ADUSER -Server $DomainName -Identity $CurrentUser $AddedUser = $CurrentUser.SamAccountName + ' , ' + $CurrentUser.GivenName + \" \" + $CurrentUser.Surname $AllUsers.Add($AddedUser) } $AllUsers | Out-File $SaveFile ","date":"2015-10-30","objectID":"/posts/powershell_get_members_of_group/:0:0","tags":["PowerShell"],"title":"PowerShell Get Members Of Group","uri":"/posts/powershell_get_members_of_group/"},{"categories":["PowerShell"],"content":"Back in May of 2014 Microsoft released a windows update – MS14-025 – that removed the ability to push out passwords to workstations remotely using group policy","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"What Happened? Back in May of 2014 Microsoft released a windows update – MS14-025 – that removed the ability to push out passwords to workstations remotely using group policy due to issues with elevation of privilege. If that patch is applied it’s a rather large pain to change the local admin after that without something like SCCM in place. ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:0:0","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"Working Around the Issue After working through some similar issues and reading a few TechNet Articles I decided to build a quick and slightly dirty powershell script to do several things as needed. This particular script does the following: ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:1:0","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"What this script does Renames the Administrator Account on a specified computer. Resets the password of that account on the specified computer. Enables or Disables the default Administrator account. Creates a Dummy Account called “Administrator” that has no rights with a static password of “P@ssword1” ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:1:1","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"What this script DOESNT do: Provide flexibility to if the password is set to expire or not. Encrypt well, anything. It’s all in raw plain text. Some other day I might go back and encrypt the password that is sent to the local administrator account. Currently process a list of computers – It could though the logic is there just not tested and used. $computers = Read-Host “What is the Computer Name?” #Enter the name of the computer you would like to modify $userPW = Read-Host “What is the Password you would like to set?” #Enter the password you would like to set for the Administrator account. $CurrentAdmin = Read-Host “What is the Current Administrator Name?” #Enter the name of the current administrator account. $DisableDefaultAdminAccount = Read-Host “If you like to Enable the Default Administrator Account enter 0. If you would like to DISABLE the account enter 2” #Enter the status you would like the Administrator account to have. Enabled or Disabled. foreach ($computer in $computers) { #This doesn’t need to be a function, I left it like this as it doesn’t hurt anything and if I Wanted to come back and actually create a LIST of computers I could. if (test-connection -computername $computer -quiet) { try { $localAdmin = [ADSI](“WinNT://” + $computer + “/” + $CurrentAdmin + “,User”) if($DisableDefaultAdminAccount -eq ‘0’){ $LocalAdmin.UserFlags = 65536 # UserFlags Value for the account to be active with a password set to never expire. $localAdmin.CommitChanges() # Commit the change } Else { $LocalAdmin.UserFlags = 66083 #UserFlags Value for the account to be Disabled with password set to never expire. $localAdmin.CommitChanges() # Commit the change } $localAdmin.psbase.rename(‘SuperAdmin’) $localAdmin.setpassword($userPW) Write-Host “Successfully Renamed Administrator Account on $computer” -fore green $ObjComputer = [ADSI](“WinNT://” + $Computer) $DummyUser = $OBJComputer.Create(“User”, “Administrator”) $DummyUser.setPassword(“P@ssword1”) $DummyUser.SetInfo() #Commit this change of a new account with this password to the SAM DB – this makes the account visable and actable upon $DummyUser.Description = “Dummy Account” #Update the description of the account once commited to SAM $DummyUser.UserFlags = 66083 $DummyUser.CommitChanges() # Commit the change of disabled and the description. Write-Host “Successfully Created Administrator Account on $computer” -fore green } catch { Write-Host “$_” -fore red } } else { Write-Host “Ping Failed to” $computer } } Some other future developments may include randomizing the password that is provided encrypting it and storing it somewhere. Please note as with everything posted here this is published as is and doesn’t promise support or that it will work well or properly even within your environment. ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:1:2","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":null,"content":"Wouldn't it be cool if we could make better Visio Drawings using SCOM Data?","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"The Question: ","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/:0:0","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"Testing Level 2 ","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/:1:0","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"Testing Level 3 “Wouldn’t it be awesome if we could create pretty Visio Drawings of our systems for the customers to look at and see up-time of servers using SCOM Data?” Well turns out in fact you can do this! It’s a feature it’s been around in SCOM for quite some time. However it’s not exactly the best documented component and certainly has a couple of pit fulls, among them the frustrating “Client Not Supported Error”. “What do you mean the client isn’t supported! I just installed the same version everything looks good SCOM WHYYYYY” It looks like this Untitled2 Why you ask? I’ll tell you why because it turns out SCOM get’s really angry at Null values in management packs. The Assumptions: First of all let me begin this with an assumption. This answer ASSUMES the following things to be true. You have correctly installed Visio Proffesional or Premium 2010/2013 on your workstation. You have correctly installed the SCOM Console and it’s pre-requisites on the workstation you are using. You have appropriate access to SCOM – (REQUIRES SCOM ADMINISTRATOR RIGHTS) You have correctly installed the SCOM For Visio Add in AFTER doing all these things and the receive the above error message. The Problem: The root cause of this problem is as previously stated a Null Value within a management pack that has been installed in your SCOM environment. Some common known examples include the Microsoft Azure Managemetn pack and the NetApp Management Pack for clusters monitoring. Essentially within the SQL tables for the management packs there is a description for the management pack component resource. Specifically icon resources “DiagramIcon” or “u16xu16Icon” and then every now and again a company simply doesn’t put anything in for that field and you get a “NULL” value. The Resolution: Let me preface this with “Your milage may vary, use this at your own risk, I am not a Microsoft Employee you can’t say I didn’t warn you, and you can’t sue me if this blows up your environment”. That being said I did get this SQL Query from a Microsoft Employee so that has to count for something. The first component of the solution is determining which management pack contains the Null Value. In order to do this we will need to do something a little scary and that is query the Operations Manager Database. This handy SQL query did the job perfectly for me: SELECT [ImageReference].[ImageId], [ImageReference].[ReferenceId], [ImageReference].[ManagementPackId], [ImageReference].TimeAdded, [ImageReference].LastModified, SUBSTRING([EnumType].EnumTypeName, 39, 100) AS ImageCategory, [MPElementView].[MPElementName], [ManagementPack].[ContentReadable] FROM dbo.ImageReference JOIN dbo.[Resource] on ([Resource].ResourceId = ImageReference.ImageId) LEFT JOIN dbo.[Category] ON [Category].CategoryTarget = [Resource].ResourceId LEFT JOIN dbo.[EnumType] ON [EnumType].EnumTypeId = [Category].CategoryValue JOIN dbo.MPElementView ON (ImageReference.ReferenceId = MPElementView.MPElementId) INNER JOIN dbo.[ManagementPack] ON dbo.ManagementPack.ManagementPackId = [ImageReference].ManagementPackId AND dbo.ManagementPack.ContentReadable = 1 WHERE dbo.[ImageReference].[ReferenceId] IN (select dbo.ManagedType.ManagedTypeId from dbo.ManagedType) and dbo.[Resource].ResourceType = 4 If this receives some feedback I will do a write up on how to actually run this query against the database complete with pictures and step by step components. This should return some information that can be either copy pasted or exported to a CSV/Excel file and reviewed. Once you’ve done this you search for the word “NULL” if this is the root cause you should find something that looks like this: NULL Data in MP’s To the right side you will then notice the descriptive name of the component in the management pack that uses the item with the null value. That is the item that is causing the problem. From this information you can then determine what vendor you either need to work with to resolve this, OR simply delete the o","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/:1:1","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"This was an old way from years ago on how to reset permissions for old File Shares.","date":"2015-06-24","objectID":"/posts/how_to_reset_permissions_on_a_users_home_directory/","tags":null,"title":"How To Reset Permissions on a Users Home Directory","uri":"/posts/how_to_reset_permissions_on_a_users_home_directory/"},{"categories":null,"content":"Below is a script, provided as is, that is a non-fancy way to reset permissions with some sense of logic on a users home directory. I’ve got a slightly better version of it, but I want to tweak a few things before posting it online. $Folder = Read-Host \"Enter the name of the user to reset permissions for\" #Enter the name of the user directory here $Existance = Get-ADUser -LDAPFilter \"(SAMAccountName=$Folder)\" $Path = '\\\\YOURNETWORKSHAREHERE' $Fullpath = $Path + $Folder #Combine the network path with the variable of the users home folder $CheckExistance = Test-Path $fullpath #Checks to make sure the path exists If ($Existance -eq $Null) { \"User Does not exist in AD\" #If you get this, the ldap filter didnt find the user in active directory. } ElseIf ($CheckExistance -Eq 'True' ){ $Confirmation = Read-Host \"Are you sure you want to edit permissions for \" $Folder \" enter Y to continue anything else to exit\" If ($Confirmation -Eq 'Y') { $User = 'YOURDOMAINHERE\\' + $Folder $Admins = 'YOURDOMAINHERE\\Domain Admins' $HomeShareManagers = 'YOURDOMAINHERE\\WHATEVEROTHERGROUPYOUWANT' $Path = $Path + $Folder icacls \"$Path\" /setowner (\"$User\") /Q /T /C #Sets the owner of the root user folder and all sub-folders to the current \"for\" user. iCacls \"$Path\" /Q /C /T /reset #Resets the all folders and files starting at the root to ONLY have the permissions granted by inheritance icacls \"$Path\" /Grant :R (\"$User\" + ':(OI)(CI)M') /Q #Grants the user in question modify rights to all objects within the root user folder. icacls \"$Path\" /Grant :R (\"$Admins\" + ':(OI)(CI)F') /Q #Grants the Domain Admins group Full control rights to all objects within the root user folder. icacls \"$Path\" /Grant :R (\"$HomeShareManagers\" + ':(OI)(CI)F') /Q #Grants the site specific Home Share Managers group Full Control within the root user folder. icacls \"$path\" /Remove Builtin /Q /T #Removes the builtin user ACL. This is auto generated and applied when a /reset is performed iCacls \"$Path\" /inheritance:R #Turns off inheritance at the root of the user folder. } } Else { 'Something Went Wrong' #Chances are in this case the folder is not named the same as the user's Login ID } ","date":"2015-06-24","objectID":"/posts/how_to_reset_permissions_on_a_users_home_directory/:0:0","tags":null,"title":"How To Reset Permissions on a Users Home Directory","uri":"/posts/how_to_reset_permissions_on_a_users_home_directory/"},{"categories":null,"content":"About Hey there, I’m Jordan. Nice to meet you. If you’ve found your way here to my about page, you’re probably looking for some information about who I am and what I do, so let me help fill in some blanks. I’m an engineer. I do engineering things. I started working in IT back in 2008, my first year of college. Somehow my resident assistant saw me playing World Of Warcraft and said: “hey, want a job,” to which I said, well, I like money, and the next thing I knew, I was building a print server. Saying yes to that simple question was probably one of my best decisions, as it led me to where I am today. I’ll be the first to admit there was no plan when I said yes. I just thought, “I’ll make some cash.” Little did I know that it would lead me down the rabbit hole of getting to build some cool stuff and have an impact on so many people. Somewhere along the way, I coined the name “JordanTheITGuy,” and it stuck, so that’s who I am, who I’ve been, and probably who I’ll always be. If you’re interested in PowerShell, Endpoint Management, Azure, or Reporting, I hope you find something useful here. Well, this is what I look like ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"}]