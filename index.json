[{"categories":["Intune"],"content":"How to find potentially risk files with LOG4J risks","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"On December 10th 2021 CVE-2021-44228 was unveiled- queue the mass panic. A simple logging component which had been around for… forever in a whole bunch of things including but not limited to Minecraft. Update: February 6th 2022 - It’s worth nothing that even now three months later this vulnerability is still having massive impact all over the world as the threat hunting methods originally devised were limited in their nature. In fact, we have even seen cases where grey hat hackers were using the exploit to patch the exploit. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:0:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Vulnerability Hunting V.S. Exploit Hunting DANGER: READ THIS Before you read any further, let me be clear, finding a “file” that has or is vulnerable to this exploit this is not the end of dealing with this vulnerability. I have tried to cover all the scenarios I can think of, however I am not a genius and there is no way to write this for every possible scenario. It’s one half of the whole. You absolutely need to start continuously hunting for the behaviors attackers would use this class for, while constantly checking for the existence of it in your environment. Hunting this threat is in and of itself challenging. When the vulnerability first came out there were several scripts that floated around the internet geared towards hunting the hashes of the vulnerable files. However as things continued to develop people started to ask – do these hashes change if someone nests a JAR inside a JAR? Additionally, what if an attacker changes the name of the product or the class is referenced in another JAR? And how do we tell the difference between something that is just not updated, and something being exploited? For more reading on that I suggest the following MSTIC team articles: Defender for Cloud finds machines affected by Log4j vulnerabilities Microsoft’s Response to CVE-2021-44228 Apache Log4j 2 – Microsoft Security Response Center ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:1:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"What can you do today with Intune Proactive Remediations? In Configuration Manager we have CI’s and they work amazingly well for hunting the state, and contents of specific files. I’m going to put a second disclaimer here, don’t use this script as an end all to everything. There is no one size fits all for this vulnerability, and in fact just saying “we patched all good” might not even be good enough for a while. Since last week, I’ve written three or four different methods to try and detect “do we need to patch this vulnerability.” All three of these methods have different pros’s and cons based on number of files, age of device, and are you looking for obfuscations. In general people have landed on three main different methods. Hash Validation, based on file name File Name Detection File Extension Detection and Class Validation The script I’m going to show uses the last of these three options. All of these have their own unique pro’s and con’s. I could spend hours on these, but I don’t think that’s why you’re here if this is something you’re interested in let me know and maybe I’ll do some type of follow up. If you’ve never created a Proactive Remediation before, rejoice because the most complicated part of creating one, is finding where they are located. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:2:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"The Script for the Proactive Remediation This article assumes you know how to create a proactive remediation, and will only be covering an explanation on the script used for detection. #Warning on potentially could scan synced sharepoint libraries. #Note this is using CIM instance - this will NOT work for old Servers and is not intended to be used on them. $drives = (Get-CimInstance -Query \"Select DeviceID from win32_logicaldisk where drivetype = 3\").DeviceID #Set the search string we are hunting for. $searchString = \"*.jar\" #Add type for reading the JarFiles Add-Type -AssemblyName \"system.io.compression.filesystem\" #Create an object to store found risks $foundRisks = New-Object -TypeName 'System.Collections.Generic.List[psobject]' Foreach ($drive in $drives) { #Assemble the risky files for the drive. $riskyFiles = (\u0026cmd /c robocopy /l $(($drive) + '\\') null \"$searchString\" /ns /njh /njs /np /nc /ndl /xjd /mt /s).trim() | Where-Object { $_ -ne \"\" } #Evaluate each set of risky files to see if there is anything to Evaluate. Foreach ($file in $riskyFiles) { $data = $null $detections = $null try{ #Warning this could could potentially create a lock on a Jar file - we do dispose of the connection and read at the end but based on size it could take a moment. $data = [io.Compression.Zipfile]::openRead($file) $detections = $data.Entries | Where-Object {$_.fullname -like \"*jndiLookup.class\"} $data.Dispose() } catch{ $hash = [ordered]@{ fileName = $file class = \"UnableToRead\" fileHash = $((Get-FileHash -Path $file -Algorithm SHA256).Hash) } $foundRisks.add((New-Object -TypeName psobject -Property $hash)) } if($detections){ foreach($detection in $detections ){ $hash = [ordered]@{ fileName = $file class = $detection.FullName fileHash = $((Get-FileHash -Path $file -Algorithm SHA256).Hash) } $foundRisks.add((New-Object -TypeName psobject -Property $hash)) } } } } If ($($foundRisks | Measure-Object).count -ge 1) { foreach($risk in $foundRisks){ #Assemble a Single Large Write Host Command for PR $jumboTune = \"$jumboTune Found: $($risk.FileName)with Hash:$($risk.fileHash)and Class: $($risk.class)`n\" } Write-Host $jumboTune exit 1 } Else { Write-Host \"No Vulnerabilities found\" exit 0 } What’s so special about this script? Well, it’s fast. No seriously it’s REALLY fast. We are talking evaluate every file in 600GB in ~19 seconds fast. Most of this is thanks to Robocopy. Now let’s break down the code and what’s happening here. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:3:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Initial Gathering of Drives #Note this is using CIM instance - this will NOT work for old Servers and is not intended to be used on them. $drives = (Get-CimInstance -Query \"Select DeviceID from win32_logicaldisk where drivetype = 3\").DeviceID #Set the search string we are hunting for. $searchString = \"*.jar\" #Add type for reading the JarFiles Add-Type -AssemblyName \"system.io.compression.filesystem\" #Create an object to store found risks $foundRisks = New-Object -TypeName 'System.Collections.Generic.List[psobject]' Nothing fancy here, just know that this is using CIM instance, assuming you’re using this script in Intune, you should only have machines that support this command. Additionally we set our search string – in this case anything that ends with “*.jar”. We add a type assemble – more on that later, and then create a list of PSObjects. Didn’t have to do that, but I like to use lists it’s a habit from when I’m not sure what version of PowerShell is in play. We then iterate over each drive and do the following: ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:3:1","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Gather Risky Files $riskyFiles = (\u0026cmd /c robocopy /l $(($drive) + '\\') null \"$searchString\" /ns /njh /njs /np /nc /ndl /xjd /mt /s).trim() | Where-Object { $_ -ne \"\" } #Evaluate each set of risky files to see if there is anything to Evaluate. Foreach ($file in $riskyFiles) { $data = $null $detections = $null try{ #Warning this could could potentially create a lock on a Jar file - we do dispose of the connection and read at the end but based on size it could take a moment. $data = [io.Compression.Zipfile]::openRead($file) $detections = $data.Entries | Where-Object {$_.fullname -like \"*jndiLookup.class\"} $data.Dispose() } catch{ $hash = [ordered]@{ fileName = $file class = \"UnableToRead\" fileHash = $((Get-FileHash -Path $file -Algorithm SHA256).Hash) } $foundRisks.add((New-Object -TypeName psobject -Property $hash)) } The first line leverages Robocopy, to gather only the string to file names using the /l command and some other switches to turn off the noise and speed ups the process of gathering the files. This then provides a list full of files with “*.Jar” at the end. Now it’s time to go to work. We use the IO.Compression.ZipFile class to open and read the contents of each of the .JAR file. We then look at all of the “entries” for anything that has the jndiLookup.class. We look for this, because if we find the class, we can be reasonable sure regardless of if there is a hash match, or if the file names don’t match that the machine is potentially at risk. We then add some important bits like where the file is located and it’s hash to our storage and continue on. We could just as easily swap this out for any of the other methods, validating if the .jar matches the known hash lists, or just reporting based on the name of the jar. If ($($foundRisks | Measure-Object).count -ge 1) { foreach($risk in $foundRisks){ #Assemble a Single Large Write Host Command for PR $jumboTune = \"$jumboTune Found: $($risk.FileName)with Hash:$($risk.fileHash)and Class: $($risk.class)`n\" } Write-Host $jumboTune exit 1 } Else { Write-Host \"No Vulnerabilities found\" exit 0 } Finally here at the end we compound together the names of the potentially vulnerable files, and write them to the host screen before existing with Exit Code 1 to properly send “risk” back to Intune. Once the script runs based you should get some nice outputs which you can then use to evaluate and start to make decisions on what should or shouldn’t be remediated. Keep in mind this doesn’t fix the issue as fixes will continue to evolve. This just helps you identify the problem. Here is an example of what the output looks like on my home machines, which happened to have an old copy of Minecraft on it. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:3:2","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["Intune"],"content":"Closing Thoughts I urge you to keep in mind that this is an evolving threat. The first “patch” to remediate the CVE was found to not always work. The second one encouraged people to just flat out remove the jndi lookup.class from the class path. I wouldn’t be surprised if we find several more things along the way. Your mileage may vary on how you look for vulnerability and I encourage you to think about what you are hunting for. Happy Patching. ","date":"2021-12-17","objectID":"/posts/find-log4j-with-intune-proactive-remediations/:4:0","tags":["PowerShell"],"title":"Find Log4J With Intune Proactive Remediations","uri":"/posts/find-log4j-with-intune-proactive-remediations/"},{"categories":["ConfigMgr"],"content":"A speedy guide on how to convert Update ID's","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"If you’ve ever worked with Automatic Deployment Rules, at some point an update has failed to download. While you might be familiar with the RuleEngine.log file, did know the “updateID” is the “CI_ID”? If you’ve ever tried to find a software update via CI_ID, you know you’re going to one of two places, and neither of them is the console. Essentially, if you’re here you’re looking for an easy way to figure out what update caused this error: For those of you who already know what this is and just want the quick answer here you go: ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:0:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"PowerShell Method #Enter the site code here $siteCode = \"XYZ\" #Enter the CI ID $ciID = \"11111111\" Get-CimInstance -ClassName SMS_SoftwareUpdate -Namespace \"root\\SMS\\site_$($SiteCode)\" -Filter \"CI_ID = $($ciID)\" | Select-Object LocalizedDisplayName,DateCreated ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:0:1","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"SQL Method --Where XXXXX is the update ID from the logs with an error SELECT*FROMv_UpdateInfoWHERECI_ID='XXXXXX'--or for more strategic data SELECTdbo.v_UpdateInfo.CI_ID,dbo.v_UpdateInfo.ArticleID,dbo.v_UpdateInfo.Title,dbo.v_UpdateInfo.CI_UniqueID,dbo.v_UpdateInfo.InfoURLFROMv_UpdateInfoWHERECI_ID='XXXXX'","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:0:2","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"What Does this Error Mean? In this scenario, the ADR has failed because it was unable to download content an example error for this might be: Failed to download ContentID 16778383 for UpdateID 16779809. Error code = 404 While this might be a pretty simple error (Can’t download the content, content not found, cause I deleted it) – what’s not clear is the name of the update causing the issue, and trying to determine the name of the update from a series of numbers might be frustrating. ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:1:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"Getting Update Info with PowerShell If you’ve worked with Configuration Manager for any length of time then you know it’s all WMI at the end of the day. In this case, software updates and their information exist within the Site Namespace, and have a class called “SMS_SoftwareUpdate”. You can actually retrieve all of the updates, and their associated properties by just requesting the objects that are of type SMS_SoftwareUpdate. This is pretty simple to get using the below line. When you do this, make sure you update line with your site code. This is pretty neat as you can get a lot of general information about software updates directly via PowerShell. Get-CimInstance -ClassName SMS_SoftwareUpdate -Namespace \"root\\SMS\\site_DM6\" If we take a close look you can see the CI_ID field here which of course means you can filter on it as was done in the example at the top of the article, so in this case we could run: #Enter the site code here $siteCode = \"XYZ\" #Enter the CI ID $ciID = \"16779809\" Get-CimInstance -ClassName SMS_SoftwareUpdate -Namespace \"root\\SMS\\site_$($SiteCode)\" -Filter \"CI_ID = $($ciID)\" | Select-Object LocalizedDisplayName,DateCreated With this we get the below output which includes the date the update was created, and the name of the update causing the issue. ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:2:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["ConfigMgr"],"content":"Getting Information with SQL We can also get this information from SQL. Fortunately the SQL information is a little more transparent in my opinion, because CI_ID is the primary key which is used in a lot of locations across the Configuration Manager Database. For this use case it’s the primary key in the view: v_UpdateInfo If we run a select * from this view we will find all of the pieces we need for this particular puzzle, and from there we can create the SQL query like we did above to find out the name of the update which was causing this issue. ","date":"2021-11-12","objectID":"/posts/automatic-deployment-rule-update-id-translation/:3:0","tags":["ConfigMgr","PowerShell"],"title":"Automatic Deployment Rule   Update ID Translation","uri":"/posts/automatic-deployment-rule-update-id-translation/"},{"categories":["Security"],"content":"Defender for Endpoint making a Client Secret to access Data, can sometimes be useful if properly controlled","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Part Two on Getting Data from Defender for Endpoint This blog is the second post in a multipart series on how to get data from Defender for endpoint and analyze the patching data that is returned. Previously, we covered how to build a token, and request data from the Defender for endpoint API. This time we will cover how to create an azure app registration that allows the minimum required permissions to gather this data. To refresh your memory on what data, and how we would acquire said data, give a read back over part one. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:0:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"What is an Azure App Registration An azure app registration, can be a rather exhaustive conversation. The core usage is to provide authentication to allow a user, or a service access to an azure tenant. Azure app registrations have changed over the years. This includes changes to the authentication library they use, and the granularity of permissions they allow. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:1:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Azure App Registration Requirements To create an azure app registration in a tenant you need some special permissions. You need to not only be able to create the app registration, but you also need to be able to approve the usage of those permissions in your organization. To do this, you will need one of three different roles. Application Administrator Application Developer Cloud Application Administrator You can read more about quickly setting up any type of app registration here: ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:2:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Creating an App Registration for Defender for Endpoint Lets walk through the process to create an azure registration that we could use to complete the earlier released post. To register, you will first need to login at portal.azure.com and then navigate to app registrations. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:0","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Creating a registration This will then launch the AAD registered apps portal, and launch the applications list blade. From here you can create a new registration, see existing registrations or troubleshoot issues. If you are not familiar with this section, this is also where you would see how your CMG connects to Azure, desktop analytics and more. For this, we will simply select ‘New Registration’ Selecting this will open the window to start creating a new registration. Creating a registration is pretty simple, just enter a name choose the scope of who can use it and give it a name. For our example, I have given the app a name ‘Defender For Endpoint API. Once you click register at the bottom of the screen you will then be presented with a small box in the top right once the app is created. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:1","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Permissions for the App Once the application exists we are ready to start adding permissions to the application. Before we add any permission we can go ahead and remove the User.Read permission as we will not need it. To do this click the three dots on the far right and select delete. We can do so by using the add a permission button under the API permissions node. This will then launch the request API permissions section. From this section select the option ‘APIs my organization uses’ This will then let you search a lot of the build in API’s that are available in the portal. We want to search for Windows Defender ATP. Then we will want to select Application Permissions to ensure that the PowerShell script only requires a token, and not a login. We could of course do a login, but this way we can use the token for automation purposes later. Choose the type of authentication We can then search for the three permissions we need Machine.Read.All Software.Read.All Vulnerability.Read.All Once each of these permissions has been found, and checked, select add permissions at the bottom of the page. Once completed it will look like this, and you will need to then grant admin consent. Granting Admin Consent will pop up a box to confirm that you would like to grant these permissions. At this time the permissions are set now we just need to create a key! ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:2","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Creating a Key AKA a Secret First we will navigate to the certificates and secrets section. Next we can create a new client secret, note for improved security usage of a certificate is also recommended for identity validation. This will then open the Add a client secret window. Select a time frame for the secrets expiration. I would recommend no more than 12 months. And select Add. This will then generate the client secret ID and the value for the secret. Make sure you save this.. IMPORTANT: Once you leave this screen the value is hidden and cannot be recovered, securely store this value. Get your tokens That’s it the secret is now generated and now we can move on to testing! ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:3","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Validation A quick stroll back to part 1 to grab the script is all we need. We then plug in, the tenant ID, application ID, and the secret. ","date":"2021-06-28","objectID":"/posts/query-defender-for-endpoint-part-2/:3:4","tags":["PowerShell","Security"],"title":"Query Defender for Endpoint Part 2","uri":"/posts/query-defender-for-endpoint-part-2/"},{"categories":["Security"],"content":"Vulnerability Management is hard.","date":"2021-01-28","objectID":"/posts/query-defender-for-endpoint-part-1/","tags":["PowerShell"],"title":"Query Defender for Endpoint Part 1","uri":"/posts/query-defender-for-endpoint-part-1/"},{"categories":["Security"],"content":"Vulnerability Management is HARD nderstanding patch compliance is mission critical task for all organizations regardless of their size or affiliation. What a lot of organizations struggle with is the different between vulnerabilities and patch compliance. As a result a lot of companies end up buying expensive third party tools to scan their environment for vulnerabilities, which happens to include your base Microsoft Patches. These vulnerability scans result in providing a huge sometimes seemingly unconquerable list for the IT department. Fortunately a large number of these vulnerabilities can be mitigated using a third party patch management solution like PatchMyPC. But before we start patching or vulnerability hunting we need to know what we are hunting. Fortunately the Defender ATP portal can make the initial vulnerability discovery easy. In this blog post the following items will be covered: Building an Authentication Token for Defender Querying the Defender for Endpoint API for vulnerabilities using PowerShell Turning that Data into a consumable CSV Report There will be future blog posts to cover the following: Creating a security key with minimal read permissions for the API Converting Vulnerability data into PowerBI Reports Querying the same data using KQL The above planned posts will be updated and linked as they are written. This blog post assumes you already have an app registration, and an API secret key in Azure AD – or have the knowledge to create one. If you do not – a new post on how to create one is scheduled for next week. Asking the right Question Before we get into automation lets jump into how we can test out different API endpoints to find out what data we would get back. Whenever I do data analytics, or build a report the first thing I do is try to make sure I’m asking, and answering the right question. If you navigate with me to securitycenter.Microsoft.com we can find to query the endpoint API without any type of automation. This way we can ensure we have the right question before we waste a bunch of time on other things. Once you click on the API Explorer you’ll be taken to a webpage that showcase different ways you can query the defender API to retrieve data. I would encourage you to use the API Explorer to test different endpoints and see what data is sent back and how. While the overall documentation for the website is pretty good, it’s confusing especially if API’s are not something you play with on a regular basis. You can use these queries to get a good idea of how the API works simply click one of the samples, for this example I’m going to chose “get 10 Vulnerabilities by machines” and then click the “run query” button. Once you click the run query button if you have any machines with vulnerabilities in the environment you’ll get a return back! This alone gives us a bunch of data that’s useful. We know the CVE-ID we know the machine ID and we can use that to find the referenced machine we need to go patch. However, this format this style isn’t very helpful and having to log into a web portal like this is probably not something we can expect a manager to do on a daily basis. Fortunately we can take the URL – presented to us above and use it with PowerShell to automate the data grab, and make it present only the data we are interested in. For this we will be using the URL: https://api-us.securitycenter.windows.com/api/vulnerabilities/machinesVulnerabilities? Asking the Right Question – With PowerShell PowerShell has a couple of different ways to query an API. However before we can even get started with querying the API we need to build our bearer token which will authenticate us to ASK questions. Fortunately this is pretty well documented on the Microsoft Website. This was theory, it's different in the real world NOTE: Everything above was theory and info, USE CAUTION on the lines below. When you query the API you could potentially pull sensitive (vulnerabilties) – information – and a LARGE amount","date":"2021-01-28","objectID":"/posts/query-defender-for-endpoint-part-1/:0:0","tags":["PowerShell"],"title":"Query Defender for Endpoint Part 1","uri":"/posts/query-defender-for-endpoint-part-1/"},{"categories":[""],"content":"How to use Sir, to integrate with Microsoft ToDo","date":"2021-01-21","objectID":"/posts/to-do-with-siri/","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":[""],"content":"It’s just after the first of the year, and I’m sure those New Years resolutions are still burning in the background of everyone’s heads. What better way to accomplish those resolutions than using the tools we have available to us! Well, I tried to use Microsoft ToDo last year. I really did. I found whenever I was sitting in front of a computer I was very dilligent in it’s usage and accomplishing things. However, when wandering around I always found myself making excuses for not taking my phone out and using the app. Further complicated by having two different tenants. A personal one with the boss lady and one for work. With the introduction of “shortcuts” in iOS I decided enough was enough. I was going to remove “having to take out my phone” as an excuse. ","date":"2021-01-21","objectID":"/posts/to-do-with-siri/:0:0","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":[""],"content":"iOS Shortcuts Beginning in iOS 13 apple by default started adding an application called “Shortcuts”. The idea being apple wanted to provide an easy set of building blocks allowing users to create automated tasks and to help fill the gaps where Siri might fall short. Some of the cool things that the shortcuts app lets you do is build home automation for anything that integrates with the apple home kit as well. A great example is something like the ability to turn a set of lights on from your home screen without having to fuss with “Find the app, open the app, find the set of lights you want on, turn them on” and then repeat the process to turn them off. I don’t particularly enjoy that process and I imagine you don’t either. ","date":"2021-01-21","objectID":"/posts/to-do-with-siri/:1:0","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":[""],"content":"Shortcut Scripting Shortcuts are interesting in how you have different options to interact with Shortcuts. When you create a new Shortcut the first thing to know is the “Name” of the shortcut is the activation phrase so when you first create a shortcut like below, the activation phrase is “Hey Siri New Shortcut” that’s not very helpful but if you click the three dots you can change it to something useful. Lets set up a quick shortcut to get something done today that will optionally remind us! Here I’ve gone ahead and created a new task on the screen called “Make a New task” so when I say “Hey Siri, make a new task” it will launch this workflow. Next I need to get some further input, because for various reasons you can’t add a variably into the startup phrase. So if you select “add action” and then choose scripting You can scroll WAAAAAAAAAAAAAY down towards the bottom and find the ask for input option. This lets you get a prompt from Siri about what you want to do. So I’ve set a picture below and I’ve cheated a little bit because I’ve put two steps into one. First I’m accepting the input, and then I’m using another action to store the result of that input into a variable called “Task Name” I’ll cover that later. One of the big benefits to the TODO application is the ability to remind us when it’s time to work on a task. And with a little more scripting we can add a conditional to determine if this task should have a reminder set. To accomplish this, we first add another block to do a test to see “Should I remdind you to get this task done” and if the answer is YES we will capture a block of time on WHEN we should remind you. Side note, in this picture, you can change all the input types when you’re testing AND the conditionals. You can also set a default answer to look for. Once we are inside the if conditional we just need to use the same ask for input action to get a DATE TIME response this time, and then use it’s result to create a new task! NOTE when you search for tasks the “TO DO” app can execute search for “Microsoft” Searching for “toDo” often returns wrong apps. Below you can see a screen shot of what it looks like. Remember that variable I mentioned earlier? Here is where it comes back into play. You use it here to ensure the name of the task is properly passed through otherwise the name you gave it earlier is thrown away. What’s really neat about these simple building blocks is how once you understand them you can put them together to increase complexity as needed using different word queues. Maybe you need a more advanced todo with notes? Just add another shortcut with some more options and variables and a different word choice cue. Or maybe you just need something simple like updating the grocery list, no reminders no nothing you just are in the middle of cooking and can’t be bothered to wash your hands to grab your phone. I hope this was helpful as I know the first time I tried to build a shortcut not everything made sense the first time. I know this wasn’t very detailed but if you want to see more content like this or more in depth automations let me know in the comments! ","date":"2021-01-21","objectID":"/posts/to-do-with-siri/:2:0","tags":[],"title":"To Do With Siri","uri":"/posts/to-do-with-siri/"},{"categories":["PowerShell"],"content":"Getting time is hard when it comes to code.","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"If you’ve ever worked in a large distributed environment you’ve likely experienced time issues. Maybe it’s not even so much an issue as you just want to know where the heck in the world a machine is. Especially in the current state of the world where almost every other day I wake up and go “WHAT YEAR IS IT” every day is Monday and everything is always on fire I’m sure you’re thinking can’t I just invoke command to it? Or maybe just enter PSSession? Well that’s what I thought too but in testing I got a mixed bag of results. ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:0:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"Enter-PSSession Get-Date For the purpose of this I have a test server: “PROBRESFS01” and my local machine “WARMACHINE”. One is in eastern time, and the other is in Pacific time. A slight difference. Now, one would assume that from here, I can run Get-Date and get the current time for PROBRESFS01. One would also be CORRECT in that assumption. This is because the sessions LOCALE information is sent across the session. However, that’s not really convenient if you need to get the time for a group of servers, say something like all distribution points in an environment. ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:1:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"Just use Invoke-Command then right? Well, kinda. Watch what happens when we use invoke command to get the current time. Huh, for some reason it’s now showing the time retrieved from the remote server in MY time. As best as I can tell, this is because PowerShell is trying to help you by converting the time back into something you can understand. When it does this it does it for your current timezone. ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:2:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":["PowerShell"],"content":"OK but then how? We can tackles this a couple of ways. The first option is just get the time zone information of the remote computer, and then convert your local machines time to it. However, that means if there is a difference in minutes between the two you won’t know about it. So what if we get both, and then convert it using .NET? $ComputerName = \"REMOTEPC\" $TimeZone = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-TimeZone} $Time = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-Date} $CurrentTime = [System.TimeZoneInfo]::ConvertTimeBySystemTimeZoneId(($Time), \"$($TimeZone.ID)\") $CurrentTime Well that’s a pretty good start. We can do better, what if we turn it into a function instead. function Get-RemoteTime { [CmdletBinding()] param( [Parameter(HelpMessage = \"The name of the remote computer\")] [string]$ComputerName ) #Get the timezone of the remote computer $TimeZone = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-TimeZone} #Get the Time of the remote computer $Time = Invoke-Command -ComputerName $ComputerName -ScriptBlock {Get-Date} $CurrentTime = [System.TimeZoneInfo]::ConvertTimeBySystemTimeZoneId(($Time), \"$($TimeZone.ID)\") return \"The current time of the remote machine is: $($CurrentTime)it's TimeZone ID is: $($TimeZone.ID)\" } Get-RemoteTime -ComputerName \"RemotePCName\" Can we take it even further beyond? Of course we can lets get the time for all DPS: note if you have a CMG it will error on that one… Remote PowerShell to a cloud DP just sounds bad. function Get-DPCurrentTime{ [CmdletBinding()] param( [Parameter(HelpMessage = \"Enter the name of the ConfigMgr Server\",Mandatory = $true)] [string]$ConfigMgrServer, [Parameter(HelpMessage = \"Enter the ConfigMgr Site Server\", Mandatory = $true)] [string]$SiteCode ) begin{} process{ $DPList = Get-WmiObject -ComputerName $ConfigMgrServer -Namespace root\\sms\\site_$SiteCode -Query \"select distinct ServerName from sms_distributionpointInfo\" $List = [System.Collections.Generic.List[object]]::new() ForEach($Server in $DPList){ $TimeZone = Invoke-Command -ComputerName $Server.ServerName -ScriptBlock {Get-TimeZone} $CurrentTime = [System.TimeZoneInfo]::ConvertTimeBySystemTimeZoneId((Get-Date), \"$($TimeZone.ID)\") $Hash = [ordered]@{ ServerName = $Server.SERVERNAME CurrentTime = $Currenttime TimeZone = $TimeZone.DisplayName } $Item = New-Object -TypeName PSobject -Property $Hash $List.Add($Item) } return $List } } https://github.com/JordanTheITGuy/PowerShell/blob/master/BlogPosts/HowTo%20-%20Get%20Local%20Time%20for%20All%20DPS/Get-LocalTimeDPS.ps1 ","date":"2020-09-14","objectID":"/posts/mr-shiba-what-time-is-it-get-time-remotely/:3:0","tags":[],"title":"Mr Shiba What Time Is It - Get Time Remotely","uri":"/posts/mr-shiba-what-time-is-it-get-time-remotely/"},{"categories":null,"content":"A short personal story about the Digital Divide and it's impact on the world.","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"The Digital Divde in Rural America is more than just a news story This blog post has been a long time coming. I feel an obligation here to inform any regular readers I have if you are expecting a technology post, this isn’t it. One additional warning, this post will get a little bit into my personal life story. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:0:0","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Some important history To understand how I ended up in the spot I’m in today there are some key things to know about my past. First, my parents got divorced when I was five. OK, nothing really interesting, happens all the time. What happens less often is your mother dying in a car crash with no last will and testament when you’re nine. Now you’re wondering how this is relevant. When a couple who has a child is divorced has no will, all of their possessions are passed on to the children, or in this case me. This included a house I started making payments on as a nine year old. Well, I didn’t but my father did as my Probate Court appointed representative. If you’re keeping score at home, I was born in 1990 – and started making house payments in 1999. This will come up later… ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:1:0","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"The beginning of the sad times with no internet “ish” Back in 2016, I lived in an apartment in the Greater Detroit area. I also started a job working for a company allowing full remote work. Things were awesome. However, within a month or two, my grandmother passed away. My grandmother 98 at the time, had been living in my house back in my home town of Hillsdale. When she passed, I suddenly had a remote job, a house, AND an apartment. Combine all these changes with how my roommate was preparing to move out to live with his now fiancé and it was time to make some decisions. I decided to move home to my small town and start working on making my house nice. I figured worst case scenario I could always use the internet at my dads shop. TLDR: My roommate in Detroit was moving out, I had an empty house in my home town, my mortgage was cheaper than any apartment I could ever get. So why pay for an apartment? ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:1:1","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Internet Options Getting ready to move back to my home town I started looking at different internet options and I was really excited! A quick glance indicated how things had changed since I left. I even saw some broadband choices. I soon learned this was a lie. What internet providers don’t tell you is how the coverage maps including the ones provided by the FCC are NOT a comprehensive picture. The way the coverage maps work basically are if any one house inside of a CENSUS block, has broadband the ISP can claim they provide coverage to the entire CENSUS block. Here is an example of a Census block where because people live on lakefront property an ISP brought a physical connection to them, one mile away from me and as a result if you navigate to the FCC website it claims everyone here has access to the following speeds from these providers. When in reality: And before people go about yelling “Oh you doxed yourself” – I’m not hiding where I live is literally government public record. I’m not hard to find. Now the inevitable answer to this is always “Oh just have cable brought to your house”. Well, of the different providers I tried to reach over the years I only ever got a response from ONE. Let me tell you their response was perfectly reasonable… The number pictured didn’t change for four years. Which brings me full circle on why PROPER reporting of where internet access specifically BROADBAND access is available in the USA is so important. The map above claims I have internet is responsible for deciding what companies get what funds. My CENSUS block, was considered NOT eligible for funding in the Connect America Phase II act. Additionally, Frontier Communications – The ONLY company with a physical hardline to my house (only capable of providing .5 – yes .5 not 5) – received $725K went bankrupt this year. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:0","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Give me Options Captain By now you’re going, why haven’t you moved, sold your house run off and joined a circus, something anything to get back to even second world internet. Well, the answer lies up above. I started making house payments when I was 9 years old. I’m now 30. 21 years of house payments. Consider the average duration of a mortgage and you have an idea of why I might not want to move. Sell my house, losing my equity, and move somewhere else. (Higher monthly cost of living, but hey internet). Use LTE Service for Internet Drive to Town and use the internet at my dad’s shop Try to find a way to trench cable through a mile of land for home internet. I tried using an ATT LTE service for a while, unfortunately (and it doesn’t matter which carrier you pick) it only sometimes worked. I mean if you call this working then I guess… On RARE occasions it might even consistently run like this: So you could technically say I had “internet” at my house for the four years I’ve lived here. Sure technically. If you consider the above – adequate internet service for an IT professional. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:1","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"OK but how did you work? Fortunately this is my home town. My dad, has owned and operated his own store since 1984 here in Hillsdale MI. He was kind enough to let me build an 8×8 office on his premises and use his internet and electricity in exchange for supporting his… less than modern equipment. This meant for me any time I needed to do anything other than maybe watch some Netflix on my phone, I had to drive the 15 minute journey to the office. As a nerd and video game lover this led to me spending almost no time at my house at all for four years. I came home to eat, sleep and play with my dogs. The rest of the time I essentially lived in town in my office. Sometimes I even brought the dogs with me. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:2","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"Enter “Barad-Dûr” or “The Tower” Prior to me moving back to “the dale” there was one other option available to me. However the trees had grown to a point where it wasn’t feasible to use. The last option was a local Point to point wireless company called DMCI Broadband. http://dmcibb.net/ Yes, I know the 90’s called they want their website back but don’t hate. The company recently started offering the ability to build a tower for you in your own backyard. So I called them, and low and behold, they could finally bring speeds up to 20mb/s to my area with a promise of 100mb/s later this year. Unfortunately in order to make it work I had to be able to clear the tree line so I could hit their radio tower: TWO MILES AWAY So, after some investigation with a bucket truck and a drone. We found we could reach their tower we started building it. It’s hard to realize how tall it is without the light fixture but 80 feet is REALLY high.. like 6-7 story building tall. The below speed test was taken this evening, the VP of the website was playing a video game next to me. The tower pictured above finally advanced the internet connection here at home past the age of the late 90’s. While the speed is not a consistent 20mbps at all, I will say the latency has been ROCK solid. Especially knowing they are increasing capacity later this month. I hope this was helpful in explaining, and I also hope no one else ever has to go through this. Additionally I hope it opens some eyes to just how disconnected Rural America STILL is. ","date":"2020-09-08","objectID":"/stories/rural-internet-in-the-usa/:2:3","tags":null,"title":"Rural Internet in the USA","uri":"/stories/rural-internet-in-the-usa/"},{"categories":null,"content":"I have no idea what I am doing...","date":"2016-02-11","objectID":"/posts/adding-email-property-in-ad/","tags":null,"title":"Adding E-Mail Property in AD","uri":"/posts/adding-email-property-in-ad/"},{"categories":null,"content":"A few months back I worked on a project to configure a password manager that was managing accounts across multiple domains without a trust. The Problem: This password management software was actually pretty cool. It’s able to match user accounts in its secure data base using a particular active directory attribute. In this case the e-mail field. Unfortunately, the users with accounts in both domains didn’t have the same e-mail attribute. In fact the resource domain for production has no e-mail address’s assigned to it almost at all. The Solution: The solution here was actually a fairly simple set of powershell code that did a few things. First, I imported a CSV file using a relationship of UserName and E-MAIL account. (Which I extracted from the primary domain you know the one where they actually HAVE the correct information) . Then using that data I read through all users that exist in the list and if I found the user, then I checked to see if they had an e-mail address. If they did I logged it and didn’t make a change. If they did NOT have an e-mail address I went ahead and gave them the correct e-mail address. It looked something like this: $DataPath = Read-Host \"Enter The file name or path here\" $AllUserData = Import-CSV $DataPath Import-Module ActiveDirectory ForEach ($User in $AllUserData){ $UserADObj = Get-ADUser -Identity $User.username -Properties Mail If ($UserADObj.mail){ $Output = \"User \" + $User.Username + \" already has an email set of \" + $UserADObj.Mail Add-Content C:\\PowershellLogs\\EMailAddressErrorLog.txt $Output } Else{ Set-ADUser $User.Username -EmailAddress $User.EMailAddress } } ","date":"2016-02-11","objectID":"/posts/adding-email-property-in-ad/:0:0","tags":null,"title":"Adding E-Mail Property in AD","uri":"/posts/adding-email-property-in-ad/"},{"categories":["Active Directory"],"content":"What in the world are protected groups in Active Directory?","date":"2015-11-03","objectID":"/posts/protected-groups-in-active-directory/","tags":["Research"],"title":"Protected Groups in Active Directory","uri":"/posts/protected-groups-in-active-directory/"},{"categories":["Active Directory"],"content":"The Question: This morning we hired a new and wonderful guy for our Help-desk and when setting up this persons account a strange oddity occured that caused one of the other helpdesk workers to come over to me and ask, “Hey why can’t I reset this new guys account? I can reset anyone else’s account but not his”. Now, I’m not proud I’ll admit at first I was stumped on this one there shouldn’t be any reason why you can’t reset his account I said – Mildly grumpy having only had one cup of coffee so far that day – Show me what you mean! Sure enough after walking over to his desk I watched him crack open AD Users and Computers and he couldn’t reset the guys password. The Assumptions: During this initial observation I made several assumptions and in order for this scenario to make sense some more information is required. This Organization does NOT use elevated accounts. It’s written in the standards document but the document hasn’t been ratified and implemented yet. The Organization DOES use delegated rights over accounts to allow certain users to be able to reset accounts that are a part of a single OU. The User attempting the modification is a member of a group that has been delegated those rights. The User who is being modified is in an OU that the other user has delegated rights over. The Problem: In a NORMAL use case scenario this wouldn’t have come up this particular challenge arose from a specific set of circumstances. The user we were attempting to modify (We’ll call him the User) and the user doing the modifying (We’ll call him the Admin for now) was created in a DIFFERENT OU than his final resting place, and prior to being moved there he was added to a security group that was NESTED in one of the Active Directory Protected Groups. What you ask, is an active Directory Protected Group? Well let’s start by listing what they are from the Microsoft Technet Website: So, what does this actually mean? Well when a user account is added to one of the protected groups a few things happen. For starters every hour Active Directory starts this wonderful process that looks at users that are a member of these protected groups. Then upon finding those members it reaches out and sets the AD attribute “AdminCount” to the value of 1. This signifies to ActiveDirectory that this account is an “Administrative” account and to disable inheritance on the object and to enforce the security of AdminSDHolder. The Resolution: Fortunately in this case the simple solution to achieve the desired behavior in this environment was “acceptable”. However, it doesn’t solve the problem as a whole. The simple one off solution is using active directory users and computers from a domain administrator account enable inheritance on the user object. This will allow the appropriate inherited permissions to flow down on to the user before locking the account again from being edited by delegation on OU’s. This however, is NOT a long term solution. The correct LONG term solution would be to create an elevated account for ANY user that NEEDS to be a member of a protected group and place them in a dedicated OU in accordance with Microsoft best practices. Currently in development here at problem resolution is a script that will regress through a users security groups and list the protected group the user is a member of as well as the group path that provided that membership. So, what does this actually mean? Well when a user account is added to one of the protected groups a few things happen. For starters every hour Active Directory starts this wonderful process that looks at users that are a member of these protected groups. Then upon finding those members it reaches out and sets the AD attribute “AdminCount” to the value of 1. This signifies to ActiveDirectory that this account is an “Administrative” account and to disable inheritance on the object and to enforce the security of AdminSDHolder. DANGER: READ THIS This post is very old and likely has outdated information in it ","date":"2015-11-03","objectID":"/posts/protected-groups-in-active-directory/:0:0","tags":["Research"],"title":"Protected Groups in Active Directory","uri":"/posts/protected-groups-in-active-directory/"},{"categories":["PowerShell"],"content":"Every now and again there comes a need to get the members of a group and manipulate that data in some fashion.","date":"2015-10-30","objectID":"/posts/powershell_get_members_of_group/","tags":["PowerShell"],"title":"PowerShell Get Members Of Group","uri":"/posts/powershell_get_members_of_group/"},{"categories":["PowerShell"],"content":"Every now and again there comes a need to get the members of a group and manipulate that data in some fashion. Now there are many ways to skin this cat and work with this data from VBscript, to utilizing DSquery to Quest Powershell CMDLETS to just raw powershell cmdlets. Rather than spend time writing a new script every time you work at a different place or having to change constants in a script I spent some time writing a quick powershell script that accepts some variable information an outputs a CSV, or TXT file (your choice) with the user’s SAMaccountName combined with first and last name for all members of that group. You can copy and download a version of the PS1 Script from Here to make sure there are no white space errors. ########################################################################## # Powershell Written by Jordan Benzing # # Last edited on 10/30/2015 # # Version 1.0.0 # # Disclaimer: This is provided as is and gaurantees no support # # Just because this script works in my environment does not mean it will # # always work in your environment. Please perform appropriate testing for# # your environment. # # Any updates will be hosted at problemresolution.wordpress.com # # # ########################################################################## $GroupName = Read-Host \"Enter the name of your group here\" $DomainName = Read-Host \"Enter the Domain you are querying here\" $SaveFile = Read-Host \"Where would you like to save the output? Example: C:\\users\\Username\\Desktop\\test.csv\" $MembersofGroup = Get-ADGroupMember -Identity $GroupName $AllUsers = {$TheUsers}.Invoke() ForEach ($Member in $MembersofGroup){ $CurrentUser = $Member.SamAccountName $CurrentUser = Get-ADUSER -Server $DomainName -Identity $CurrentUser $AddedUser = $CurrentUser.SamAccountName + ' , ' + $CurrentUser.GivenName + \" \" + $CurrentUser.Surname $AllUsers.Add($AddedUser) } $AllUsers | Out-File $SaveFile ","date":"2015-10-30","objectID":"/posts/powershell_get_members_of_group/:0:0","tags":["PowerShell"],"title":"PowerShell Get Members Of Group","uri":"/posts/powershell_get_members_of_group/"},{"categories":["PowerShell"],"content":"Back in May of 2014 Microsoft released a windows update – MS14-025 – that removed the ability to push out passwords to workstations remotely using group policy","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"What Happened? Back in May of 2014 Microsoft released a windows update – MS14-025 – that removed the ability to push out passwords to workstations remotely using group policy due to issues with elevation of privilege. If that patch is applied it’s a rather large pain to change the local admin after that without something like SCCM in place. ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:0:0","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"Working Around the Issue After working through some similar issues and reading a few TechNet Articles I decided to build a quick and slightly dirty powershell script to do several things as needed. This particular script does the following: ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:1:0","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"What this script does Renames the Administrator Account on a specified computer. Resets the password of that account on the specified computer. Enables or Disables the default Administrator account. Creates a Dummy Account called “Administrator” that has no rights with a static password of “P@ssword1” ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:1:1","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":["PowerShell"],"content":"What this script DOESNT do: Provide flexibility to if the password is set to expire or not. Encrypt well, anything. It’s all in raw plain text. Some other day I might go back and encrypt the password that is sent to the local administrator account. Currently process a list of computers – It could though the logic is there just not tested and used. $computers = Read-Host “What is the Computer Name?” #Enter the name of the computer you would like to modify $userPW = Read-Host “What is the Password you would like to set?” #Enter the password you would like to set for the Administrator account. $CurrentAdmin = Read-Host “What is the Current Administrator Name?” #Enter the name of the current administrator account. $DisableDefaultAdminAccount = Read-Host “If you like to Enable the Default Administrator Account enter 0. If you would like to DISABLE the account enter 2” #Enter the status you would like the Administrator account to have. Enabled or Disabled. foreach ($computer in $computers) { #This doesn’t need to be a function, I left it like this as it doesn’t hurt anything and if I Wanted to come back and actually create a LIST of computers I could. if (test-connection -computername $computer -quiet) { try { $localAdmin = [ADSI](“WinNT://” + $computer + “/” + $CurrentAdmin + “,User”) if($DisableDefaultAdminAccount -eq ‘0’){ $LocalAdmin.UserFlags = 65536 # UserFlags Value for the account to be active with a password set to never expire. $localAdmin.CommitChanges() # Commit the change } Else { $LocalAdmin.UserFlags = 66083 #UserFlags Value for the account to be Disabled with password set to never expire. $localAdmin.CommitChanges() # Commit the change } $localAdmin.psbase.rename(‘SuperAdmin’) $localAdmin.setpassword($userPW) Write-Host “Successfully Renamed Administrator Account on $computer” -fore green $ObjComputer = [ADSI](“WinNT://” + $Computer) $DummyUser = $OBJComputer.Create(“User”, “Administrator”) $DummyUser.setPassword(“P@ssword1”) $DummyUser.SetInfo() #Commit this change of a new account with this password to the SAM DB – this makes the account visable and actable upon $DummyUser.Description = “Dummy Account” #Update the description of the account once commited to SAM $DummyUser.UserFlags = 66083 $DummyUser.CommitChanges() # Commit the change of disabled and the description. Write-Host “Successfully Created Administrator Account on $computer” -fore green } catch { Write-Host “$_” -fore red } } else { Write-Host “Ping Failed to” $computer } } Some other future developments may include randomizing the password that is provided encrypting it and storing it somewhere. Please note as with everything posted here this is published as is and doesn’t promise support or that it will work well or properly even within your environment. ","date":"2015-10-27","objectID":"/posts/powershell_change_localadminpassword/:1:2","tags":["PowerShell"],"title":"Powershell Change The Local Administrator Account/Password","uri":"/posts/powershell_change_localadminpassword/"},{"categories":null,"content":"Wouldn't it be cool if we could make better Visio Drawings using SCOM Data?","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"The Question: ","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/:0:0","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"Testing Level 2 ","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/:1:0","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"Testing Level 3 “Wouldn’t it be awesome if we could create pretty Visio Drawings of our systems for the customers to look at and see up-time of servers using SCOM Data?” Well turns out in fact you can do this! It’s a feature it’s been around in SCOM for quite some time. However it’s not exactly the best documented component and certainly has a couple of pit fulls, among them the frustrating “Client Not Supported Error”. “What do you mean the client isn’t supported! I just installed the same version everything looks good SCOM WHYYYYY” It looks like this Untitled2 Why you ask? I’ll tell you why because it turns out SCOM get’s really angry at Null values in management packs. The Assumptions: First of all let me begin this with an assumption. This answer ASSUMES the following things to be true. You have correctly installed Visio Proffesional or Premium 2010/2013 on your workstation. You have correctly installed the SCOM Console and it’s pre-requisites on the workstation you are using. You have appropriate access to SCOM – (REQUIRES SCOM ADMINISTRATOR RIGHTS) You have correctly installed the SCOM For Visio Add in AFTER doing all these things and the receive the above error message. The Problem: The root cause of this problem is as previously stated a Null Value within a management pack that has been installed in your SCOM environment. Some common known examples include the Microsoft Azure Managemetn pack and the NetApp Management Pack for clusters monitoring. Essentially within the SQL tables for the management packs there is a description for the management pack component resource. Specifically icon resources “DiagramIcon” or “u16xu16Icon” and then every now and again a company simply doesn’t put anything in for that field and you get a “NULL” value. The Resolution: Let me preface this with “Your milage may vary, use this at your own risk, I am not a Microsoft Employee you can’t say I didn’t warn you, and you can’t sue me if this blows up your environment”. That being said I did get this SQL Query from a Microsoft Employee so that has to count for something. The first component of the solution is determining which management pack contains the Null Value. In order to do this we will need to do something a little scary and that is query the Operations Manager Database. This handy SQL query did the job perfectly for me: SELECT[ImageReference].[ImageId],[ImageReference].[ReferenceId],[ImageReference].[ManagementPackId],[ImageReference].TimeAdded,[ImageReference].LastModified,SUBSTRING([EnumType].EnumTypeName,39,100)ASImageCategory,[MPElementView].[MPElementName],[ManagementPack].[ContentReadable]FROMdbo.ImageReferenceJOINdbo.[Resource]on([Resource].ResourceId=ImageReference.ImageId)LEFTJOINdbo.[Category]ON[Category].CategoryTarget=[Resource].ResourceIdLEFTJOINdbo.[EnumType]ON[EnumType].EnumTypeId=[Category].CategoryValueJOINdbo.MPElementViewON(ImageReference.ReferenceId=MPElementView.MPElementId)INNERJOINdbo.[ManagementPack]ONdbo.ManagementPack.ManagementPackId=[ImageReference].ManagementPackIdANDdbo.ManagementPack.ContentReadable=1WHEREdbo.[ImageReference].[ReferenceId]IN(selectdbo.ManagedType.ManagedTypeIdfromdbo.ManagedType)anddbo.[Resource].ResourceType=4If this receives some feedback I will do a write up on how to actually run this query against the database complete with pictures and step by step components. This should return some information that can be either copy pasted or exported to a CSV/Excel file and reviewed. Once you’ve done this you search for the word “NULL” if this is the root cause you should find something that looks like this: NULL Data in MP’s To the right side you will then notice the descriptive name of the component in the management pack that uses the item with the null value. That is the item that is causing the problem. From this information you can then determine what vendor you either need to work with to resolve this, OR simply delete the offending management pack and it’s components. I imagine there m","date":"2015-10-21","objectID":"/posts/client_server_version_error_in_scom_2012r2_visio/:1:1","tags":null,"title":"Visio 2010/2013 Client Server Version Error in SCOM 2012R2 Visio Drawings","uri":"/posts/client_server_version_error_in_scom_2012r2_visio/"},{"categories":null,"content":"This was an old way from years ago on how to reset permissions for old File Shares.","date":"2015-06-24","objectID":"/posts/how_to_reset_permissions_on_a_users_home_directory/","tags":null,"title":"How To Reset Permissions on a Users Home Directory","uri":"/posts/how_to_reset_permissions_on_a_users_home_directory/"},{"categories":null,"content":"Below is a script, provided as is, that is a non-fancy way to reset permissions with some sense of logic on a users home directory. I’ve got a slightly better version of it, but I want to tweak a few things before posting it online. $Folder = Read-Host \"Enter the name of the user to reset permissions for\" #Enter the name of the user directory here $Existance = Get-ADUser -LDAPFilter \"(SAMAccountName=$Folder)\" $Path = '\\\\YOURNETWORKSHAREHERE' $Fullpath = $Path + $Folder #Combine the network path with the variable of the users home folder $CheckExistance = Test-Path $fullpath #Checks to make sure the path exists If ($Existance -eq $Null) { \"User Does not exist in AD\" #If you get this, the ldap filter didnt find the user in active directory. } ElseIf ($CheckExistance -Eq 'True' ){ $Confirmation = Read-Host \"Are you sure you want to edit permissions for \" $Folder \" enter Y to continue anything else to exit\" If ($Confirmation -Eq 'Y') { $User = 'YOURDOMAINHERE\\' + $Folder $Admins = 'YOURDOMAINHERE\\Domain Admins' $HomeShareManagers = 'YOURDOMAINHERE\\WHATEVEROTHERGROUPYOUWANT' $Path = $Path + $Folder icacls \"$Path\" /setowner (\"$User\") /Q /T /C #Sets the owner of the root user folder and all sub-folders to the current \"for\" user. iCacls \"$Path\" /Q /C /T /reset #Resets the all folders and files starting at the root to ONLY have the permissions granted by inheritance icacls \"$Path\" /Grant :R (\"$User\" + ':(OI)(CI)M') /Q #Grants the user in question modify rights to all objects within the root user folder. icacls \"$Path\" /Grant :R (\"$Admins\" + ':(OI)(CI)F') /Q #Grants the Domain Admins group Full control rights to all objects within the root user folder. icacls \"$Path\" /Grant :R (\"$HomeShareManagers\" + ':(OI)(CI)F') /Q #Grants the site specific Home Share Managers group Full Control within the root user folder. icacls \"$path\" /Remove Builtin /Q /T #Removes the builtin user ACL. This is auto generated and applied when a /reset is performed iCacls \"$Path\" /inheritance:R #Turns off inheritance at the root of the user folder. } } Else { 'Something Went Wrong' #Chances are in this case the folder is not named the same as the user's Login ID } ","date":"2015-06-24","objectID":"/posts/how_to_reset_permissions_on_a_users_home_directory/:0:0","tags":null,"title":"How To Reset Permissions on a Users Home Directory","uri":"/posts/how_to_reset_permissions_on_a_users_home_directory/"},{"categories":null,"content":"How Did I get started in IT Hey there, I’m Jordan. Nice to meet you. If you’ve found your way here to my about page, you’re probably looking for some information about who I am and what I do, so let me help fill in some blanks. I’m an engineer. I do engineering things. I started working in IT back in 2008, my first year of college. Somehow my resident assistant saw me playing World Of Warcraft and said: “hey, want a job,” to which I said, well, I like money, and the next thing I knew, I was building a print server. Saying yes to that simple question was probably one of my best decisions, as it led me to where I am today. I’ll be the first to admit there was no plan when I said yes. I just thought, “I’ll make some cash.” Little did I know that it would lead me down the rabbit hole of getting to build some cool stuff and have an impact on so many people. Somewhere along the way, I coined the name “JordanTheITGuy,” and it stuck, so that’s who I am, who I’ve been, and probably who I’ll always be. If you’re interested in PowerShell, Endpoint Management, Azure, or Reporting, I hope you find something useful here. ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"I used to be a consultant, I used to but I still am too. ","date":"0001-01-01","objectID":"/consulting/:0:0","tags":null,"title":"Consulting","uri":"/consulting/"}]